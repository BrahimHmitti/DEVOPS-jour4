#!/bin/bash

# ========================================
# SCRIPT AUTOMATIQUE TP DEVOPS JOUR 4
# DÃ©ploiement complet : RÃ©silience + Monitoring + Chaos Engineering + CI/CD
# ========================================

set -e  # ArrÃªt en cas d'erreur

echo "ğŸš€ DÃ‰BUT DU TP DEVOPS JOUR 4 - AUTOMATISÃ‰"
echo "========================================"

# Couleurs pour l'affichage
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

print_section() {
    echo -e "\n${BLUE}========================================${NC}"
    echo -e "${BLUE}$1${NC}"
    echo -e "${BLUE}========================================${NC}\n"
}

print_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}âš ï¸ $1${NC}"
}

print_error() {
    echo -e "${RED}âŒ $1${NC}"
}

wait_for_pods() {
    local namespace=$1
    local timeout=${2:-300}
    echo "â³ Attente que tous les pods soient prÃªts dans le namespace $namespace..."
    kubectl wait --for=condition=ready pod --all -n $namespace --timeout=${timeout}s || true
    sleep 10
}

# ========================================
# PARTIE 1: PRÃ‰PARATION CLUSTER
# ========================================

print_section "PARTIE 1: PRÃ‰PARATION CLUSTER MINIKUBE"

echo "ğŸ”§ VÃ©rification et nettoyage cluster existant..."
minikube delete || true

echo "ğŸ”§ CrÃ©ation cluster minikube 2 nÅ“uds..."
minikube start --nodes 2 --cpus 3 --memory 4096

echo "ğŸ“Š VÃ©rification des nÅ“uds..."
kubectl get nodes

print_success "Cluster minikube 2 nÅ“uds crÃ©Ã©"

# ========================================
# PARTIE 2: TOPOLOGY SPREAD CONSTRAINTS
# ========================================

print_section "PARTIE 2: DÃ‰PLOIEMENT APPLICATION RÃ‰SILIENTE"

echo "ğŸ“¦ DÃ©ploiement application rÃ©siliente..."
kubectl apply -f resilient-app-deployment.yaml

echo "ğŸŒ CrÃ©ation services d'exposition..."
kubectl apply -f resilient-app-service.yaml

echo "â³ Attente dÃ©ploiement application rÃ©siliente..."
wait_for_pods "default"

echo "ğŸ“Š VÃ©rification rÃ©partition des pods..."
kubectl get pods -o wide | grep resilient

print_success "Application rÃ©siliente dÃ©ployÃ©e avec Topology Spread Constraints"

# Test de rÃ©silience
echo "ğŸ”¥ Test de rÃ©silience - Simulation panne nÅ“ud..."
kubectl drain minikube-m02 --ignore-daemonsets --delete-emptydir-data --force || true
sleep 10

echo "ğŸ“Š Ã‰tat aprÃ¨s drainage..."
kubectl get pods -o wide | grep resilient

echo "ğŸ”„ Remise en service du nÅ“ud..."
kubectl uncordon minikube-m02
sleep 10

echo "ğŸ“Š Ã‰tat aprÃ¨s remise en service..."
kubectl get pods -o wide | grep resilient

print_success "Test de rÃ©silience validÃ©"

# ========================================
# PARTIE 3: MONITORING PROMETHEUS/GRAFANA
# ========================================

print_section "PARTIE 3: DÃ‰PLOIEMENT STACK MONITORING"

echo "ğŸ“‹ Ajout repository Helm Prometheus..."
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update

echo "ğŸ“¦ DÃ©ploiement stack kube-prometheus-stack..."
helm install prometheus prometheus-community/kube-prometheus-stack \
    --namespace monitoring --create-namespace \
    --wait --timeout=15m

echo "â³ Attente stack monitoring..."
wait_for_pods "monitoring" 600

echo "ğŸ”‘ RÃ©cupÃ©ration password Grafana..."
GRAFANA_PASSWORD=$(kubectl get secret -n monitoring prometheus-grafana -o jsonpath="{.data.admin-password}" | base64 -d)

echo "ğŸŒ CrÃ©ation port-forward Grafana (arriÃ¨re-plan)..."
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80 &
GRAFANA_PID=$!

echo "ğŸŒ CrÃ©ation port-forward Prometheus (arriÃ¨re-plan)..."
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090 &
PROMETHEUS_PID=$!

sleep 5

echo "ğŸ§ª Test accÃ¨s Grafana..."
curl -s http://localhost:3000/api/health || print_warning "Grafana pas encore accessible"

print_success "Stack Prometheus/Grafana dÃ©ployÃ©e"
echo "ğŸ“‹ ACCÃˆS GRAFANA:"
echo "   URL: http://localhost:3000"
echo "   Username: admin"
echo "   Password: $GRAFANA_PASSWORD"

# ========================================
# PARTIE 4: INGRESS ET TESTS DE CHARGE
# ========================================

print_section "PARTIE 4: CONFIGURATION INGRESS ET TESTS"

echo "ğŸ”§ Activation addon ingress minikube..."
minikube addons enable ingress

echo "â³ Attente controller ingress..."
kubectl wait --for=condition=ready pod --all -n ingress-nginx --timeout=300s

echo "ğŸ“¦ DÃ©ploiement application guestbook..."
kubectl apply -f guestbook-deployment.yaml

echo "ğŸŒ Configuration ingress..."
kubectl apply -f guestbook-ingress.yaml

echo "ğŸŒ DÃ©marrage minikube tunnel (arriÃ¨re-plan)..."
sudo -b minikube tunnel

echo "â³ Attente application guestbook..."
wait_for_pods "default"

echo "ğŸŒ Configuration port-forward ingress pour tests..."
kubectl port-forward -n ingress-nginx svc/ingress-nginx-controller 8081:80 &
INGRESS_PID=$!

sleep 5

echo "ğŸ§ª Test accÃ¨s application via ingress..."
curl -H "Host: guestbook.fbi.com" http://localhost:8081 | head -3

echo "ğŸš€ Tests de charge (50 requÃªtes)..."
for i in {1..50}; do
    curl -s -H "Host: guestbook.fbi.com" http://localhost:8081 > /dev/null && echo -n "."
    sleep 0.1
done
echo ""

print_success "Ingress configurÃ© et tests de charge effectuÃ©s"

# ========================================
# PARTIE 5: APPLICATION AVEC MÃ‰TRIQUES CUSTOM
# ========================================

print_section "PARTIE 5: APPLICATION AVEC MÃ‰TRIQUES CUSTOM"

echo "ğŸ“¦ DÃ©ploiement application avec mÃ©triques..."
kubectl apply -f guestbook-with-metrics.yaml

echo "â³ Attente application avec mÃ©triques..."
wait_for_pods "default"

echo "ğŸŒ Port-forward application mÃ©triques..."
kubectl port-forward service/guestbook-metrics-service 8082:80 &
METRICS_PID=$!

sleep 5

echo "ğŸ§ª Test endpoint /info avec mÃ©triques custom..."
curl http://localhost:8082/info

print_success "Application avec mÃ©triques custom dÃ©ployÃ©e"

# ========================================
# PARTIE 6: CHAOS ENGINEERING
# ========================================

print_section "PARTIE 6: DÃ‰PLOIEMENT CHAOS MESH"

echo "ğŸ“‹ Ajout repository Helm Chaos Mesh..."
helm repo add chaos-mesh https://charts.chaos-mesh.org
helm repo update

echo "ğŸ“¦ DÃ©ploiement Chaos Mesh..."
helm install chaos-mesh chaos-mesh/chaos-mesh \
    --namespace chaos-mesh --create-namespace \
    --set dashboard.create=true \
    --wait --timeout=10m

echo "â³ Attente Chaos Mesh..."
wait_for_pods "chaos-mesh"

echo "ğŸŒ Port-forward dashboard Chaos Mesh..."
kubectl port-forward -n chaos-mesh svc/chaos-dashboard 2333:2333 &
CHAOS_PID=$!

sleep 5

echo "ğŸ§ª Test accÃ¨s dashboard Chaos Mesh..."
curl -s http://localhost:2333 | head -3 || print_warning "Dashboard Chaos Mesh pas encore accessible"

# CrÃ©ation expÃ©rience pod-kill
echo "ğŸ’¥ CrÃ©ation expÃ©rience pod-kill..."
cat > pod-kill-experiment.yaml << EOF
apiVersion: chaos-mesh.org/v1alpha1
kind: PodChaos
metadata:
  name: guestbook-pod-kill
  namespace: default
spec:
  action: pod-kill
  mode: one
  duration: "30s"
  selector:
    labelSelectors:
      app: guestbook
  scheduler:
    cron: "@every 2m"
EOF

kubectl apply -f pod-kill-experiment.yaml

print_success "Chaos Mesh dÃ©ployÃ© avec expÃ©rience pod-kill"
echo "ğŸ“‹ ACCÃˆS CHAOS MESH:"
echo "   URL: http://localhost:2333"

# ========================================
# PARTIE 7: GITHUB ACTIONS RUNNER
# ========================================

print_section "PARTIE 7: GITHUB ACTIONS RUNNER SELF-HOSTED"

print_warning "GitHub Runner nÃ©cessite un token personnel"
echo "ğŸ“‹ Pour crÃ©er le token:"
echo "   1. Allez dans Settings > Actions > Runners"
echo "   2. Cliquez 'New self-hosted runner'"
echo "   3. Copiez le token affichÃ©"
echo ""
echo "ğŸ“ Ensuite exÃ©cutez:"
echo "   kubectl create secret generic github-runner-token --from-literal=token=VOTRE_TOKEN"

# Template deployment runner
cat > github-runner-deployment.yaml << EOF
apiVersion: apps/v1
kind: Deployment
metadata:
  name: github-runner
spec:
  replicas: 1
  selector:
    matchLabels:
      app: github-runner
  template:
    metadata:
      labels:
        app: github-runner
    spec:
      containers:
      - name: runner
        image: sumologic/github-runner:latest
        env:
        - name: GITHUB_TOKEN
          valueFrom:
            secretKeyRef:
              name: github-runner-token
              key: token
        - name: GITHUB_OWNER
          value: "BrahimHmitti"
        - name: GITHUB_REPOSITORY
          value: "DEVOPS-jour4"
        volumeMounts:
        - name: docker-sock
          mountPath: /var/run/docker.sock
      volumes:
      - name: docker-sock
        hostPath:
          path: /var/run/docker.sock
EOF

echo "ğŸ“„ Template GitHub Runner crÃ©Ã©: github-runner-deployment.yaml"

print_success "Configuration GitHub Runner prÃ©parÃ©e"

# ========================================
# RÃ‰CAPITULATIF FINAL
# ========================================

print_section "RÃ‰CAPITULATIF FINAL - ACCÃˆS AUX SERVICES"

echo "ğŸŒ SERVICES ACCESSIBLES:"
echo "   ğŸ“Š Grafana:      http://localhost:3000 (admin/$GRAFANA_PASSWORD)"
echo "   ğŸ“ˆ Prometheus:   http://localhost:9090"
echo "   ğŸŒ Guestbook:    http://localhost:8081 (Host: guestbook.fbi.com)"
echo "   ğŸ“Š MÃ©triques:    http://localhost:8082/info"
echo "   ğŸ’¥ Chaos Mesh:   http://localhost:2333"
echo ""

echo "ğŸ”§ COMMANDES UTILES:"
echo "   kubectl get pods --all-namespaces"
echo "   kubectl get ingress"
echo "   kubectl get chaos -n chaos-mesh"
echo ""

echo "ğŸ“‹ PIDS DES PORT-FORWARDS (pour kill si besoin):"
echo "   Grafana: $GRAFANA_PID"
echo "   Prometheus: $PROMETHEUS_PID"
echo "   Ingress: $INGRESS_PID"
echo "   MÃ©triques: $METRICS_PID"
echo "   Chaos: $CHAOS_PID"

print_success "TP DEVOPS JOUR 4 TERMINÃ‰ AVEC SUCCÃˆS!"
echo ""
echo "ğŸ“ TOUT EST DÃ‰PLOYÃ‰ ET FONCTIONNEL:"
echo "   âœ… Cluster rÃ©silient avec Topology Spread Constraints"
echo "   âœ… Monitoring complet Prometheus + Grafana"
echo "   âœ… Tests de charge via Ingress"
echo "   âœ… MÃ©triques applicatives custom"
echo "   âœ… Chaos Engineering avec Chaos Mesh"
echo "   ğŸ“ GitHub Runner (template prÃªt)"
echo ""
echo "ğŸ“š Consultez apprentissage.md et how-to-start.md pour plus de dÃ©tails!"

# Fonction cleanup pour arrÃªter les port-forwards
cleanup() {
    echo "ğŸ§¹ Nettoyage des port-forwards..."
    kill $GRAFANA_PID $PROMETHEUS_PID $INGRESS_PID $METRICS_PID $CHAOS_PID 2>/dev/null || true
}

trap cleanup EXIT

echo "ğŸ”„ Appuyez sur Ctrl+C pour arrÃªter les port-forwards et nettoyer"
echo "ğŸ’¡ Ou laissez tourner pour continuer Ã  utiliser les services"

# Garde le script actif pour maintenir les port-forwards
wait