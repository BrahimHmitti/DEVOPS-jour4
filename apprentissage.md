# üìö Apprentissages DevOps - Jour 4

> üéì **TP Complet** : Infrastructure r√©siliente, Monitoring, Chaos Engineering, CI/CD et GitOps


---

# üî∑ CE QUE J'AI APPRIS ET R√âALIS√â

## PARTIE 0 : Architecture Multi-Nodes Kubernetes

J'ai cr√©√© un cluster minikube avec 2 n≈ìuds pour simuler un environnement de production r√©el. J'ai compris que la multi-node architecture est essentielle pour tester la r√©silience des applications. C'est la base de tout ce que j'ai fait apr√®s.

**Commande utilis√©e :**
```bash
minikube start --nodes 2 --driver=docker --cpus=2 --memory=3500
```

**Ce que j'ai retenu :** Un seul n≈ìud ne suffit jamais pour tester la haute disponibilit√©. J'ai appris √† v√©rifier la sant√© des n≈ìuds avec `kubectl get nodes` et √† comprendre les r√¥les control-plane vs worker.

---

## PARTIE 1 : Topology Spread Constraints

J'ai d√©couvert un m√©canisme hyper puissant pour distribuer les pods intelligemment. Les Topology Spread Constraints permettent de s'assurer qu'une application ne se retrouve pas enti√®rement sur un seul n≈ìud.

**Fichier cr√©√© :** `resilient-app-deployment.yaml`

**Configuration cl√© :**
```yaml
topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: DoNotSchedule
```

**Test de r√©silience effectu√© :** J'ai drain√© un n≈ìud avec `kubectl drain` et j'ai vu les pods se redistribuer automatiquement. C'√©tait impressionnant de voir Kubernetes respecter les contraintes m√™me pendant une panne simul√©e.

**Le√ßon importante :** `whenUnsatisfiable: DoNotSchedule` cr√©e des pods Pending si la contrainte ne peut pas √™tre respect√©e. C'est voulu - mieux vaut attendre que de violer la r√®gle de distribution.

---

## PARTIE 2 : Prometheus et Grafana

J'ai d√©ploy√© toute une stack de monitoring via Helm. √áa m'a ouvert les yeux sur l'importance de l'observabilit√©. Sans m√©triques, on est aveugle.

**Installation via Helm :**
```bash
helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack -n monitoring
```

**Ce que j'ai appris :**
- Prometheus scrape automatiquement les m√©triques des pods avec des annotations
- Grafana vient avec des dashboards pr√©-configur√©s pour Kubernetes
- AlertManager permet de configurer des alertes (Slack, email, etc.)

**Mot de passe Grafana :** Le secret s'appelle `kube-prometheus-stack-grafana` et contient le mot de passe en base64.

**Retour d'exp√©rience :** Le d√©ploiement prend 5-10 minutes avec beaucoup de CRDs (ServiceMonitor, PrometheusRule, etc.). Il faut √™tre patient et ne pas paniquer devant les warnings Helm.

---

## PARTIE 3 : Ingress NGINX et Load Testing

J'ai configur√© l'Ingress pour exposer mon application avec un nom de domaine. Ensuite j'ai fait des tests de charge pour voir comment elle r√©agit.

**Fichiers cr√©√©s :**
- `guestbook-ingress.yaml` - Configuration Ingress avec host `guestbook.fbi.com`
- `load-test.js` - Script k6 pour bombarder l'application

**Point important :** `minikube tunnel` est n√©cessaire pour que l'Ingress obtienne une IP externe. Sans √ßa, pas d'acc√®s depuis l'ext√©rieur du cluster.

**Test de charge :** J'ai envoy√© 100+ requ√™tes avec k6 et curl. J'ai vu dans Grafana les requ√™tes se r√©partir sur les 3 replicas du deployment. La distribution √©tait parfaite.

**Ce que j'ai compris :** L'Ingress fait du load balancing automatique entre les pods du Service. Pas besoin de configuration suppl√©mentaire.

---

## PARTIE 4 : Dashboard Grafana Personnalis√©

J'ai cr√©√© une application qui expose ses propres m√©triques au format Prometheus. √áa m'a fait comprendre comment instrumenter du code.

**Fichier cr√©√© :** `guestbook-with-metrics.yaml`

**Endpoint /info :**
```
# TYPE http_requests_total counter
http_requests_total{method="GET",status="200"} 12345
# TYPE app_active_users gauge
app_active_users 42
```

**Annotation importante pour Prometheus :**
```yaml
annotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "80"
  prometheus.io/path: "/info"
```

**Le√ßon :** Prometheus d√©couvre automatiquement les endpoints gr√¢ce aux annotations. Dans Grafana, j'ai pu cr√©er un dashboard custom avec ces m√©triques. C'est puissant pour monitorer des m√©triques business (utilisateurs actifs, transactions, etc.).

---

## PARTIE 5 : Chaos Engineering avec Chaos Mesh
 J'ai install√© Chaos Mesh pour casser volontairement des pods et tester si l'application survit.

**Installation :**
```bash
helm install chaos-mesh chaos-mesh/chaos-mesh -n chaos-mesh --create-namespace
```

**Exp√©rience cr√©√©e :** `chaos-pod-kill-experiment.yaml`

Cette exp√©rience tue un pod guestbook toutes les 2 minutes pendant 30 secondes. Le but ? V√©rifier que l'application reste accessible malgr√© les pannes.

**R√©sultat :** Gr√¢ce aux 3 replicas et √† l'Ingress, l'application n'a jamais √©t√© down. Les requ√™tes √©taient rout√©es vers les pods survivants. La magie de Kubernetes !

**Ce que j'ai appris :** Le Chaos Engineering n'est pas une destruction gratuite. C'est une m√©thode scientifique pour valider la r√©silience. Chaos Mesh offre plein de types d'exp√©riences : network delay, IO errors, stress CPU, etc.

---

## PARTIE 6 : GitHub Runner Self-Hosted

J'ai d√©ploy√© un runner GitHub Actions directement dans mon cluster Kubernetes. √áa permet d'ex√©cuter les pipelines CI/CD dans mon propre environnement.

**Fichier cr√©√© :** `github-runner-deployment.yaml`




**Avantages du runner self-hosted :**
- Pas de limite de minutes CI/CD (gratuit)
- Acc√®s direct au cluster Kubernetes
- Possibilit√© d'utiliser des images Docker custom
- Contr√¥le total sur l'environnement d'ex√©cution

**Configuration correcte :** 
- ‚úÖ Token stock√© via `kubectl create secret` (PAS dans le YAML)
- ‚úÖ Token √† r√©g√©n√©rer sur GitHub Settings > Actions > Runners > New
- ‚ö†Ô∏è Le token expire apr√®s 1h selon les consignes

**Point d'attention :** J'ai mont√© `/var/run/docker.sock` pour permettre au runner de builder des images Docker. C'est puissant mais √ßa donne beaucoup de privil√®ges.

---

## PARTIE 7 : Pipeline CI/CD GitHub Actions

J'ai cr√©√© un workflow complet qui build, scan et push des images Docker automatiquement √† chaque commit.

**Fichier cr√©√© :** `.github/workflows/docker-build.yaml`

**√âtapes du pipeline :**
1. **Checkout** du code
2. **Build Docker** avec BuildKit et cache
3. **Push** vers Docker Hub (tags `latest` + SHA)
4. **Scan Trivy** pour d√©tecter les vuln√©rabilit√©s
5. **Upload** des r√©sultats vers GitHub Security

**Ce que j'ai ador√© :** Le scan Trivy d√©tecte automatiquement les CVE dans l'image. Les r√©sultats apparaissent dans l'onglet Security de GitHub. C'est du DevSecOps !

**Secrets configur√©s :**
- `DOCKER_USERNAME` : Mon username Docker Hub
- `DOCKER_PASSWORD` : Token d'acc√®s Docker Hub

**Le√ßon :** Jamais de credentials en dur dans le code. Toujours utiliser les secrets GitHub/Kubernetes.

---

## PARTIE 8 : Renovate Bot

J'ai d√©ploy√© Renovate pour automatiser les mises √† jour de d√©pendances. Plus besoin de surveiller manuellement les nouvelles versions.

**Fichier cr√©√© :** `renovate-deployment.yaml`

**Configuration :** CronJob qui s'ex√©cute tous les jours √† 2h du matin. Il scanne le repo et cr√©e des Pull Requests pour :
- Mettre √† jour les images Docker dans les YAML
- Updater les versions de Helm charts
- Proposer les nouvelles versions de d√©pendances

**Automerge :** J'ai configur√© l'automerge pour les mises √† jour minor/patch. Les mises √† jour major n√©cessitent une review humaine (breaking changes possibles).

**Ce que √ßa m'apporte :** S√©curit√© (patches de vuln√©rabilit√©s) + Maintenance continue sans effort. C'est un vrai gain de temps.

---

# üöÄ CE QUI M'A LE PLUS MARQU√â

## 1. La puissance du GitOps
Avoir Git comme source de v√©rit√© change TOUT. Plus de config manuelle, plus de "√ßa marche sur ma machine". Un commit = un d√©ploiement. Un revert 


## 2. Le Chaos Engineering n'est pas destructif
on a souvent  peur de casser nos cluster. En fait, le Chaos Engineering est super contr√¥l√© : dur√©e limit√©e, scope pr√©cis, rollback automatique. C'est rassurant.



# üìù COMMANDES QUE J'UTILISE TOUT LE TEMPS

```bash
kubectl get all --all-namespaces
kubectl describe pod <pod-name>
kubectl logs -f <pod-name>
kubectl get events --sort-by='.lastTimestamp'
kubectl top nodes
kubectl top pods
kubectl port-forward svc/<service-name> <local-port>:<remote-port>
helm list --all-namespaces
minikube status
minikube tunnel
```

