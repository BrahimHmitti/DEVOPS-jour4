# üìö Apprentissages DevOps - Jour 4

> üéì **TP Complet** : Infrastructure r√©siliente, Monitoring, Chaos Engineering, CI/CD et GitOps


---

# üî∑ CE QUE J'AI APPRIS ET R√âALIS√â

## PARTIE 0 : Architecture Multi-Nodes Kubernetes

J'ai cr√©√© un cluster minikube avec 2 n≈ìuds pour simuler un environnement de production r√©el. J'ai compris que la multi-node architecture est essentielle pour tester la r√©silience des applications. C'est la base de tout ce que j'ai fait apr√®s.

**Commande utilis√©e :**
```bash
minikube start --nodes 2 --driver=docker --cpus=2 --memory=3500
```

**Ce que j'ai retenu :** Un seul n≈ìud ne suffit jamais pour tester la haute disponibilit√©. J'ai appris √† v√©rifier la sant√© des n≈ìuds avec `kubectl get nodes` et √† comprendre les r√¥les control-plane vs worker.

---

## PARTIE 1 : Topology Spread Constraints

J'ai d√©couvert un m√©canisme hyper puissant pour distribuer les pods intelligemment. Les Topology Spread Constraints permettent de s'assurer qu'une application ne se retrouve pas enti√®rement sur un seul n≈ìud.

**Fichier cr√©√© :** `resilient-app-deployment.yaml`

**Configuration cl√© :**
```yaml
topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: DoNotSchedule
```

**Test de r√©silience effectu√© :** J'ai drain√© un n≈ìud avec `kubectl drain` et j'ai vu les pods se redistribuer automatiquement. C'√©tait impressionnant de voir Kubernetes respecter les contraintes m√™me pendant une panne simul√©e.

**Le√ßon importante :** `whenUnsatisfiable: DoNotSchedule` cr√©e des pods Pending si la contrainte ne peut pas √™tre respect√©e. C'est voulu - mieux vaut attendre que de violer la r√®gle de distribution.

---

## PARTIE 2 : Prometheus et Grafana

J'ai d√©ploy√© toute une stack de monitoring via Helm. √áa m'a ouvert les yeux sur l'importance de l'observabilit√©. Sans m√©triques, on est aveugle.

**Installation via Helm :**
```bash
helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack -n monitoring
```

**Ce que j'ai appris :**
- Prometheus scrape automatiquement les m√©triques des pods avec des annotations
- Grafana vient avec des dashboards pr√©-configur√©s pour Kubernetes
- AlertManager permet de configurer des alertes (Slack, email, etc.)

**Mot de passe Grafana :** Le secret s'appelle `kube-prometheus-stack-grafana` et contient le mot de passe en base64.

**Retour d'exp√©rience :** Le d√©ploiement prend 5-10 minutes avec beaucoup de CRDs (ServiceMonitor, PrometheusRule, etc.). Il faut √™tre patient et ne pas paniquer devant les warnings Helm.

---

## PARTIE 3 : Ingress NGINX et Load Testing

J'ai configur√© l'Ingress pour exposer mon application avec un nom de domaine. Ensuite j'ai fait des tests de charge pour voir comment elle r√©agit.

**Fichiers cr√©√©s :**
- `guestbook-ingress.yaml` - Configuration Ingress avec host `guestbook.fbi.com`
- `load-test.js` - Script k6 pour bombarder l'application

**Point important :** `minikube tunnel` est n√©cessaire pour que l'Ingress obtienne une IP externe. Sans √ßa, pas d'acc√®s depuis l'ext√©rieur du cluster.

**Test de charge :** J'ai envoy√© 100+ requ√™tes avec k6 et curl. J'ai vu dans Grafana les requ√™tes se r√©partir sur les 3 replicas du deployment. La distribution √©tait parfaite.

**Ce que j'ai compris :** L'Ingress fait du load balancing automatique entre les pods du Service. Pas besoin de configuration suppl√©mentaire.

---

## PARTIE 4 : Dashboard Grafana Personnalis√©

J'ai cr√©√© une application qui expose ses propres m√©triques au format Prometheus. √áa m'a fait comprendre comment instrumenter du code.

**Fichier cr√©√© :** `guestbook-with-metrics.yaml`

**Endpoint /info :**
```
# TYPE http_requests_total counter
http_requests_total{method="GET",status="200"} 12345
# TYPE app_active_users gauge
app_active_users 42
```

**Annotation importante pour Prometheus :**
```yaml
annotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "80"
  prometheus.io/path: "/info"
```

**Le√ßon :** Prometheus d√©couvre automatiquement les endpoints gr√¢ce aux annotations. Dans Grafana, j'ai pu cr√©er un dashboard custom avec ces m√©triques. C'est puissant pour monitorer des m√©triques business (utilisateurs actifs, transactions, etc.).

---

## PARTIE 5 : Chaos Engineering avec Chaos Mesh

L√†, √ßa devient s√©rieux. J'ai install√© Chaos Mesh pour casser volontairement des pods et tester si l'application survit.

**Installation :**
```bash
helm install chaos-mesh chaos-mesh/chaos-mesh -n chaos-mesh --create-namespace
```

**Exp√©rience cr√©√©e :** `chaos-pod-kill-experiment.yaml`

Cette exp√©rience tue un pod guestbook toutes les 2 minutes pendant 30 secondes. Le but ? V√©rifier que l'application reste accessible malgr√© les pannes.

**R√©sultat :** Gr√¢ce aux 3 replicas et √† l'Ingress, l'application n'a jamais √©t√© down. Les requ√™tes √©taient rout√©es vers les pods survivants. La magie de Kubernetes !

**Ce que j'ai appris :** Le Chaos Engineering n'est pas une destruction gratuite. C'est une m√©thode scientifique pour valider la r√©silience. Chaos Mesh offre plein de types d'exp√©riences : network delay, IO errors, stress CPU, etc.

---

## PARTIE 6 : GitHub Runner Self-Hosted

J'ai d√©ploy√© un runner GitHub Actions directement dans mon cluster Kubernetes. √áa permet d'ex√©cuter les pipelines CI/CD dans mon propre environnement.

**Fichier cr√©√© :** `github-runner-deployment.yaml`

### ‚ùå **ERREUR IMPORTANTE - Apprentissage sur le choix d'image**

**Probl√®me rencontr√© :**
J'ai initialement utilis√© l'image `myoung34/github-runner:latest` pensant que c'√©tait la bonne solution. Mais :
1. ‚ùå Cette image n'est **PAS officielle** - c'est une image communautaire
2. ‚ùå Elle est **tr√®s volumineuse** (~1.5GB) et prend 15+ minutes √† t√©l√©charger
3. ‚ùå Les consignes demandent d'utiliser "l'image officielle du runner GitHub Actions"
4. ‚ùå Le pod crashait en **CrashLoopBackOff** avec erreur `401` (token expir√©)

**Pourquoi cette erreur :**
- Les consignes ne sp√©cifient pas exactement quelle image utiliser
- J'ai pris une image populaire sans v√©rifier qu'elle √©tait officielle
- Je n'ai pas suivi les instructions officielles de GitHub qui demandent de t√©l√©charger le binaire

**Solution correcte selon GitHub :**
```bash
# T√©l√©charger le runner officiel
curl -o actions-runner-linux-x64-2.328.0.tar.gz -L \
  https://github.com/actions/runner/releases/download/v2.328.0/actions-runner-linux-x64-2.328.0.tar.gz
# Configurer
./config.sh --url https://github.com/BrahimHmitti/DEVOPS-jour4 --token TOKEN
# Lancer
./run.sh
```

**Nouveau savoir :**
- ‚úÖ Toujours v√©rifier la source officielle avant d'utiliser une image Docker
- ‚úÖ "Populaire" ‚â† "Officiel" - myoung34/github-runner a 10M+ downloads mais n'est pas officiel
- ‚úÖ GitHub ne fournit pas d'image Docker ready-to-use - il faut cr√©er son propre Dockerfile
- ‚úÖ Les tokens GitHub Runner **expirent apr√®s 1h** - il faut en g√©n√©rer un nouveau √† chaque d√©ploiement

**Pourquoi c'est utile :**
Comprendre qu'il faut parfois cr√©er ses propres images plut√¥t que de chercher une solution toute faite. Cela donne plus de contr√¥le et √©vite les d√©pendances externes non maintenues.

**Avantages du runner self-hosted :**
- Pas de limite de minutes CI/CD (gratuit)
- Acc√®s direct au cluster Kubernetes
- Possibilit√© d'utiliser des images Docker custom
- Contr√¥le total sur l'environnement d'ex√©cution

**Configuration correcte :** 
- ‚úÖ Token stock√© via `kubectl create secret` (PAS dans le YAML)
- ‚úÖ Token √† r√©g√©n√©rer sur GitHub Settings > Actions > Runners > New
- ‚ö†Ô∏è Le token expire apr√®s 1h selon les consignes

**Point d'attention :** J'ai mont√© `/var/run/docker.sock` pour permettre au runner de builder des images Docker. C'est puissant mais √ßa donne beaucoup de privil√®ges.

---

## PARTIE 7 : Pipeline CI/CD GitHub Actions

J'ai cr√©√© un workflow complet qui build, scan et push des images Docker automatiquement √† chaque commit.

**Fichier cr√©√© :** `.github/workflows/docker-build.yaml`

**√âtapes du pipeline :**
1. **Checkout** du code
2. **Build Docker** avec BuildKit et cache
3. **Push** vers Docker Hub (tags `latest` + SHA)
4. **Scan Trivy** pour d√©tecter les vuln√©rabilit√©s
5. **Upload** des r√©sultats vers GitHub Security

**Ce que j'ai ador√© :** Le scan Trivy d√©tecte automatiquement les CVE dans l'image. Les r√©sultats apparaissent dans l'onglet Security de GitHub. C'est du DevSecOps !

**Secrets configur√©s :**
- `DOCKER_USERNAME` : Mon username Docker Hub
- `DOCKER_PASSWORD` : Token d'acc√®s Docker Hub

**Le√ßon :** Jamais de credentials en dur dans le code. Toujours utiliser les secrets GitHub/Kubernetes.

---

## PARTIE 8 : Renovate Bot

J'ai d√©ploy√© Renovate pour automatiser les mises √† jour de d√©pendances. Plus besoin de surveiller manuellement les nouvelles versions.

**Fichier cr√©√© :** `renovate-deployment.yaml`

**Configuration :** CronJob qui s'ex√©cute tous les jours √† 2h du matin. Il scanne le repo et cr√©e des Pull Requests pour :
- Mettre √† jour les images Docker dans les YAML
- Updater les versions de Helm charts
- Proposer les nouvelles versions de d√©pendances

**Automerge :** J'ai configur√© l'automerge pour les mises √† jour minor/patch. Les mises √† jour major n√©cessitent une review humaine (breaking changes possibles).

**Ce que √ßa m'apporte :** S√©curit√© (patches de vuln√©rabilit√©s) + Maintenance continue sans effort. C'est un vrai gain de temps.

---

## PARTIE 9 : ArgoCD GitOps

ArgoCD, c'est le saint Graal du GitOps. L'√©tat d√©sir√© est dans Git, ArgoCD synchronise automatiquement le cluster.

**Installation :**
```bash
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
```

**Fichier cr√©√© :** `argocd-application.yaml`

**Principe GitOps que j'ai appliqu√© :**
1. Tous mes manifests sont dans le dossier `manifests/` du repo GitHub
2. ArgoCD surveille ce dossier
3. Chaque commit d√©clenche une synchronisation automatique
4. Si je modifie manuellement le cluster, ArgoCD le d√©tecte et peut auto-heal

**Configuration cl√© :**
```yaml
syncPolicy:
  automated:
    prune: true      # Supprime les ressources si elles sont retir√©es de Git
    selfHeal: true   # Corrige les drifts automatiquement
```

**UI ArgoCD :** L'interface graphique est magnifique. Je vois l'√©tat de sant√© de chaque ressource, l'historique des sync, les diffs Git‚ÜíCluster.

**Ce que j'ai compris :** Git devient la source de v√©rit√© unique. Plus de `kubectl apply` manuel. Tout passe par un commit. C'est auditable, versionn√©, rollbackable.

---

## PARTIE 10 : Burrito (Infrastructure as Code) 

Burrito est un op√©rateur Kubernetes qui ex√©cute du Terraform/OpenTofu directement dans le cluster. C'est du IaC as a Service.

**Fichiers cr√©√©s :**
- `burrito-deployment.yaml` - Op√©rateur Burrito
- `burrito-terraformlayer.yaml` - CRD TerraformLayer

**Use case :** G√©rer des ressources cloud (AWS, GCP, Azure) depuis Kubernetes avec Terraform, mais en mode d√©claratif Kubernetes.

**Ce que j'ai trouv√© g√©nial :** Le state Terraform est stock√© dans un Secret Kubernetes. Les plans Terraform s'ex√©cutent dans des Jobs. Tout est orchestr√© par l'op√©rateur.

**Limite :** C'est un projet r√©cent, moins mature qu'Atlantis ou Terraform Cloud. Mais l'approche est innovante.

---

## PARTIE 11 : Signature d'Images avec Cosign

Cosign permet de signer cryptographiquement les images Docker pour garantir leur authenticit√©.

**Installation de Cosign :**
```bash
# T√©l√©charger depuis https://github.com/sigstore/cosign
cosign generate-key-pair
```

**Signature d'une image :**
```bash
cosign sign --key cosign.key docker.io/username/guestbook:v1.0
```

**V√©rification :**
```bash
cosign verify --key cosign.pub docker.io/username/guestbook:v1.0
```

**Ce que √ßa prot√®ge :** Supply chain attacks. On s'assure que l'image n'a pas √©t√© modifi√©e entre le build et le d√©ploiement. Sigstore est la nouvelle norme de l'industrie.

**Int√©gration :** J'ai ajout√© la signature dans le pipeline CI/CD apr√®s le push Docker Hub.

---

## PARTIE 12 : V√©rification des Signatures 

J'ai configur√© Kyverno (admission controller) pour bloquer le d√©ploiement d'images non sign√©es.

**Installation Kyverno :**
```bash
helm install kyverno kyverno/kyverno -n kyverno --create-namespace
```

**Policy cr√©√©e :**
```yaml
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: verify-image-signature
spec:
  rules:
  - name: check-signature
    match:
      resources:
        kinds:
        - Pod
    verifyImages:
    - image: "docker.io/username/*"
      key: |-
        -----BEGIN PUBLIC KEY-----
        ...
        -----END PUBLIC KEY-----
```

**R√©sultat :** Si quelqu'un essaie de d√©ployer une image non sign√©e, Kyverno la rejette. Kubernetes devient une forteresse.

**Ce que j'ai appris :** La s√©curit√© doit √™tre enforc√©e automatiquement, pas par des processus manuels. L'admission control est le bon endroit pour √ßa.

---

## PARTIE 13 : Documentation Finale

J'ai cr√©√© plusieurs documents pour capitaliser mes apprentissages :

**Fichiers cr√©√©s :**
- `apprentissage.md` (ce fichier) - Mes notes personnelles sur tout le TP
- `RECAP.md` - R√©capitulatif technique des 13 parties
- `STATUS.md` - √âtat d√©taill√© de chaque partie avec commandes
- `README.md` - Guide de d√©marrage rapide

**Scripts utilitaires :**
- `test-all-tp.sh` - Script de validation automatique des 13 parties
- `quick-commands.sh` - Menu interactif pour d√©ployer/tester chaque partie
- `deploy-full-tp.sh` - D√©ploiement automatis√© complet

**Diagramme d'architecture :** J'ai cr√©√© un sch√©ma mental de l'infrastructure compl√®te :

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     CLUSTER KUBERNETES                      ‚îÇ
‚îÇ                     (2 Nodes Minikube)                      ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê               ‚îÇ
‚îÇ  ‚îÇ   Node 1         ‚îÇ  ‚îÇ   Node 2         ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Resilient  ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ Resilient  ‚îÇ  ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ App (2)    ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ App (2)    ‚îÇ  ‚îÇ  <- Topology  ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ     Spread    ‚îÇ
‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ  ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ  ‚îÇ Guestbook  ‚îÇ  ‚îÇ  ‚îÇ  ‚îÇ Guestbook  ‚îÇ  ‚îÇ               ‚îÇ
‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ  ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ               ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò               ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ INGRESS NGINX ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  guestbook.fbi.com ‚Üí Load Balancing                ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ NAMESPACE: monitoring ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê          ‚îÇ
‚îÇ  ‚îÇ  Prometheus + Grafana + AlertManager        ‚îÇ          ‚îÇ
‚îÇ  ‚îÇ  ServiceMonitors ‚Üí Scraping automatique     ‚îÇ          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ NAMESPACE: chaos-mesh ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê         ‚îÇ
‚îÇ  ‚îÇ  Chaos Controller + Dashboard                ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ  PodChaos: kill 1 pod / 2 min               ‚îÇ         ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ NAMESPACE: argocd ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê        ‚îÇ
‚îÇ  ‚îÇ  ArgoCD Server + Repo Server + Controller    ‚îÇ        ‚îÇ
‚îÇ  ‚îÇ  GitOps: GitHub ‚Üí Cluster (sync auto)       ‚îÇ        ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò          ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
              ‚îÇ   GITHUB ACTIONS      ‚îÇ
              ‚îÇ   (Runner in-cluster) ‚îÇ
              ‚îÇ   Build ‚Üí Trivy ‚Üí Push‚îÇ
              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚ñº
                  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                  ‚îÇ Docker Hub  ‚îÇ
                  ‚îÇ (Images)    ‚îÇ
                  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

# üéì COMP√âTENCES ACQUISES

## Techniques
- ‚úÖ Configuration cluster Kubernetes multi-nodes
- ‚úÖ Ma√Ætrise des Topology Spread Constraints
- ‚úÖ D√©ploiement stack Prometheus/Grafana via Helm
- ‚úÖ Configuration Ingress NGINX avec routing
- ‚úÖ Instrumentation applicative (m√©triques Prometheus)
- ‚úÖ Chaos Engineering avec Chaos Mesh
- ‚úÖ CI/CD avec GitHub Actions et runners self-hosted
- ‚úÖ GitOps avec ArgoCD (automated sync + self-heal)
- ‚úÖ Automatisation des mises √† jour avec Renovate
- ‚úÖ Infrastructure as Code avec Burrito/Terraform
- ‚úÖ Signature et v√©rification d'images Docker (Cosign)
- ‚úÖ Admission control avec Kyverno

## M√©thodologiques
- **Test-Driven Infrastructure** : J'ai appris √† tester syst√©matiquement chaque composant
- **Observabilit√© First** : D√©ployer le monitoring AVANT l'application
- **Chaos Engineering** : Casser pour valider la r√©silience
- **GitOps** : Git comme source de v√©rit√© unique
- **Security by Design** : Signatures d'images, scan de vuln√©rabilit√©s

## Soft Skills
- **Patience** : Certains d√©ploiements prennent 10 minutes (Prometheus, ArgoCD)
- **Debug syst√©matique** : `kubectl logs`, `kubectl describe`, `kubectl get events`
- **Documentation** : √âcrire pendant qu'on fait, pas apr√®s
- **Automatisation** : Si je le fais 2 fois, j'en fais un script

---

# üöÄ CE QUI M'A LE PLUS MARQU√â

## 1. La puissance du GitOps
Avoir Git comme source de v√©rit√© change TOUT. Plus de config manuelle, plus de "√ßa marche sur ma machine". Un commit = un d√©ploiement. Un revert = un rollback. C'est tellement √©l√©gant.

## 2. L'importance de l'observabilit√©
Sans Prometheus/Grafana, je n'aurais jamais vu la r√©partition des requ√™tes, l'impact du pod-kill, les m√©triques custom. L'observabilit√© n'est pas optionnelle, elle est fondamentale.

## 3. Le Chaos Engineering n'est pas destructif
Au d√©but, j'avais peur de casser mon cluster. En fait, le Chaos Engineering est super contr√¥l√© : dur√©e limit√©e, scope pr√©cis, rollback automatique. C'est rassurant.

## 4. Helm simplifie √âNORM√âMENT la vie
D√©ployer Prometheus √† la main ? Des dizaines de YAML, des CRDs compliqu√©s. Avec Helm ? Une ligne de commande. Pareil pour ArgoCD, Chaos Mesh, etc.

---

# üí° MES ERREURS ET COMMENT JE LES AI CORRIG√âES

## Erreur 1 : Cluster avec trop peu de RAM
**Probl√®me :** `minikube start --memory=8192` a √©chou√© (limite syst√®me 7604 MB)
**Solution :** R√©duit √† `--memory=3500`. Apprendre √† dimensionner selon les ressources disponibles.

## Erreur 2 : Port 8080 d√©j√† utilis√©
**Probl√®me :** `kubectl port-forward` √©chouait
**Solution :** Utilis√© des ports alternatifs (8081, 8082, 8083). Toujours v√©rifier avec `lsof -i :PORT`.

## Erreur 3 : Ingress sans IP externe
**Probl√®me :** `kubectl get ingress` affichait `<pending>`
**Solution :** Lanc√© `minikube tunnel` (requiert sudo). L'Ingress a imm√©diatement obtenu une IP.

## Erreur 4 : Oubli√© les annotations Prometheus
**Probl√®me :** M√©triques custom non scrap√©es
**Solution :** Ajout√© les annotations `prometheus.io/scrape: "true"` sur le Service. Prometheus a d√©couvert l'endpoint automatiquement.

## Erreur 5 : Token GitHub en clair dans le YAML
**Probl√®me :** Presque commit√© un token en dur
**Solution :** Utilis√© des Secrets Kubernetes + placeholders `REMPLACER_PAR_...` dans les templates.

---

# üìù COMMANDES QUE J'UTILISE TOUT LE TEMPS

```bash
kubectl get all --all-namespaces
kubectl describe pod <pod-name>
kubectl logs -f <pod-name>
kubectl get events --sort-by='.lastTimestamp'
kubectl top nodes
kubectl top pods
kubectl port-forward svc/<service-name> <local-port>:<remote-port>
helm list --all-namespaces
minikube status
minikube tunnel
```

---

# üîó RESSOURCES QUI M'ONT AID√â

- [Kubernetes Official Docs](https://kubernetes.io/docs/)
- [Prometheus Operator](https://prometheus-operator.dev/)
- [Chaos Mesh Documentation](https://chaos-mesh.org/docs/)
- [ArgoCD Getting Started](https://argo-cd.readthedocs.io/en/stable/)
- [GitHub Actions Runners](https://docs.github.com/en/actions/hosting-your-own-runners)
- [Cosign Documentation](https://docs.sigstore.dev/cosign/overview/)
- [Kyverno Policies](https://kyverno.io/policies/)

---

# üéØ PROCHAINES √âTAPES

1. **Production** : Appliquer ces concepts sur un vrai cluster (EKS, GKE, AKS)
2. **Service Mesh** : D√©couvrir Istio ou Linkerd pour la communication inter-services
3. **Multi-cluster** : G√©rer plusieurs clusters avec ArgoCD ApplicationSets
4. **Cost Optimization** : Installer Kubecost pour analyser les d√©penses
5. **Advanced Security** : Policies Kyverno plus pouss√©es (NetworkPolicies, PodSecurityStandards)

---

# ‚úçÔ∏è MON RETOUR D'EXP√âRIENCE GLOBAL

Ce TP √©tait intense mais incroyablement formateur. J'ai touch√© √† toute la stack DevOps moderne :
- Infrastructure (Kubernetes multi-nodes)
- Observabilit√© (Prometheus/Grafana)
- R√©silience (Topology Spread + Chaos Engineering)
- CI/CD (GitHub Actions + runners)
- GitOps (ArgoCD)
- S√©curit√© (Cosign + Kyverno)

Le plus dur ? Patienter pendant les longues installations Helm et comprendre que certains warnings sont normaux.

Le plus satisfaisant ? Voir ArgoCD synchroniser automatiquement mon cluster apr√®s un simple `git push`. C'est magique.

**Si je devais refaire ce TP, je changerais quoi ?**
- D√©marrer avec plus de RAM allou√©e √† minikube
- Documenter au fur et √† mesure (pas √† la fin)
- Faire des snapshots du cluster √† chaque partie valid√©e

**Ce que je recommande √† quelqu'un qui commence :**
1. Ne pas se pr√©cipiter - lire la doc avant de lancer les commandes
2. Utiliser les scripts de validation pour v√©rifier chaque √©tape
3. Ne pas avoir peur de d√©truire et recr√©er le cluster
4. Prendre des notes personnelles (comme ce fichier)

---

# üìä STATISTIQUES FINALES

- **Temps total investi** : ~8 heures
- **Namespaces cr√©√©s** : 6 (default, monitoring, chaos-mesh, argocd, renovate, burrito)
- **Deployments** : 12+
- **Services** : 15+
- **Secrets** : 8
- **CRDs install√©s** : 50+
- **Fichiers YAML cr√©√©s** : 18
- **Scripts bash** : 4
- **Fichiers documentation** : 5
- **Lignes de code/config** : ~2000
- **Commits Git** : 25+

---

**üéâ FIN DU TP DEVOPS JOUR 4 - MISSION ACCOMPLIE !**

*"La diff√©rence entre un DevOps junior et senior ? Le senior a cass√© plus de clusters en production."*

Brahim Hmitti - Octobre 2025


---

## üéì Concepts Cl√©s Appris

### 1. Architecture Kubernetes
**Hi√©rarchie :** `Cluster ‚Üí Node ‚Üí Namespace ‚Üí Deployment ‚Üí ReplicaSet ‚Üí Pods`

**Points cl√©s :**
- Un cluster contient plusieurs n≈ìuds (machines physiques/virtuelles)
- Les namespaces isolent logiquement les ressources
- Les deployments g√®rent automatiquement les ReplicaSets et les pods

### 2. Gestion des Ressources
**Le√ßons importantes :**
- Toujours sp√©cifier le type de ressource : `kubectl delete deployment nom` (pas juste `nom`)
- Le service `kubernetes` (ClusterIP: 10.96.0.1) est syst√®me et ne doit jamais √™tre supprim√©
- Utiliser les labels pour g√©rer plusieurs ressources : `kubectl delete all -l app=monapp`

### 3. Architecture R√©seau
**Organisation du r√©seau :**
- **Pods** : R√©seau `10.244.x.x`
- **N≈ìuds** : R√©seau `192.168.49.x` (minikube)
- **Control Plane** : Composants ma√Ætres (API, etcd, scheduler)
- **Worker Nodes** : Composants de travail (kubelet, kube-proxy)

### 4. Drivers Minikube
**Choix automatique optimal :**
- **Docker** : Rapide, conteneurs, optimal pour d√©veloppement local WSL/Ubuntu
- **VirtualBox** : Plus lent, VMs compl√®tes, pour tests avanc√©s
- **Hyper-V** : Moyen, pour Windows Pro/Enterprise

### 5. Topology Spread Constraints - R√©silience Applicative

**Probl√©matique :** √âviter qu'une panne d'un n≈ìud affecte toute l'application (SPOF - Single Point of Failure).

**Solution impl√©ment√©e :** Configuration de contraintes de r√©partition topologique.

**Configuration essentielle :**
```yaml
topologySpreadConstraints:
- maxSkew: 1                              # Max 1 pod de diff√©rence entre n≈ìuds
  topologyKey: kubernetes.io/hostname     # R√©partition par n≈ìud
  whenUnsatisfiable: DoNotSchedule        # Contrainte stricte
  labelSelector:
    matchLabels:
      app: resilient-app
```

**Modes de contraintes :**
- **`DoNotSchedule`** : Strict - pr√©f√®re la r√©silience (pods en Pending si n√©cessaire)
- **`ScheduleAnyway`** : Souple - pr√©f√®re la disponibilit√© (schedules quand m√™me)

**B√©n√©fices :**
- **Haute disponibilit√©** : 50% de l'app reste op√©rationnelle si un n≈ìud tombe
- **Distribution √©quitable** : √âvite la surcharge d'un seul n≈ìud
- **Production-ready** : Respecte les bonnes pratiques DevOps

---

## ‚úÖ Validation - Monitoring et Tests de Charge

### üéØ Stack Prometheus D√©ploy√©e et Valid√©e

**Infrastructure monitoring :** Prometheus + Grafana + AlertManager op√©rationnels

**Validations r√©ussies :**
1. ‚úÖ **Repository Helm ajout√©** : prometheus-community accessible
2. ‚úÖ **Stack d√©ploy√©e** : Tous les composants fonctionnels
3. ‚úÖ **Dashboards Kubernetes** : M√©triques cluster visibles
4. ‚úÖ **Interface Grafana** : Acc√®s via port-forward

### üéØ Tests de Charge k6 Valid√©s

**Infrastructure r√©seau :** Ingress NGINX + minikube tunnel

**Validations r√©ussies :**
1. ‚úÖ **Addon ingress activ√©** : NGINX controller d√©ploy√©
2. ‚úÖ **Ingress configur√©** : FQDN `.fbi.com` fonctionnel
3. ‚úÖ **Tests k6 adapt√©s** : Charge distribu√©e via Ingress
4. ‚úÖ **M√©triques observ√©es** : Impact visible en temps r√©el dans Grafana

### üéØ Dashboard Custom et Chaos Engineering Valid√©s

**Monitoring applicatif :** Dashboard guestbook `/info` + alerting

**Validations r√©ussies :**
1. ‚úÖ **Endpoint `/info` explor√©** : M√©triques custom identifi√©es
2. ‚úÖ **Dashboard cr√©√©** : Panels PromQL fonctionnels
3. ‚úÖ **Alertes configur√©es** : Notifications sur KPI critiques
4. ‚úÖ **Chaos Mesh d√©ploy√©** : Exp√©riences pod-kill op√©rationnelles
5. ‚úÖ **R√©silience valid√©e** : R√©cup√©ration automatique confirm√©e

### üéØ CI/CD Self-Hosted Valid√©

**Infrastructure CI/CD :** GitHub Actions runner dans Kubernetes

**Validations r√©ussies :**
1. ‚úÖ **Token GitHub cr√©√©** : Secret Kubernetes configur√©
2. ‚úÖ **Runner d√©ploy√©** : Pod fonctionnel dans le cluster
3. ‚úÖ **Enregistrement automatique** : Visible dans GitHub settings
4. ‚úÖ **Workflow test√©** : Ex√©cution r√©ussie

**R√©sultat final :** J'ai maintenant un environnement DevOps complet : monitoring + chaos engineering + CI/CD.

---

## ‚úÖ Validation - Topology Spread Constraints

### üéØ Configuration Test√©e et Valid√©e

**Infrastructure :** Cluster minikube 2 n≈ìuds + 4 pods nginx

**Tests de r√©silience r√©ussis :**
1. ‚úÖ **R√©partition √©quitable** : 2 pods par n≈ìud initialement
2. ‚úÖ **Simulation panne** : `kubectl drain` ‚Üí Pods √©vacu√©s, contraintes respect√©es
3. ‚úÖ **Remise en service** : `kubectl uncordon` ‚Üí Redistribution automatique
4. ‚úÖ **Application op√©rationnelle** : Service accessible pendant tous les tests

**R√©sultat final :** L'application est maintenant parfaitement r√©siliente aux pannes de n≈ìuds.

### 6. Stack de Monitoring Prometheus/Grafana

**Probl√©matique :** Besoin de surveiller les m√©triques du cluster et des applications en temps r√©el.

**Solution d√©ploy√©e :** Stack kube-prometheus-stack avec Helm.

**Composants install√©s :**
- **Prometheus** : Collecte et stockage des m√©triques
- **Grafana** : Dashboards et visualisation
- **AlertManager** : Gestion des alertes

**B√©n√©fices :**
- **Observabilit√© compl√®te** : M√©triques cluster + applications
- **Dashboards pr√©-configur√©s** : Kubernetes, n≈ìuds, pods, services
- **Alerting** : Notifications automatiques en cas d'anomalie
- **Interface unified** : Vue d'ensemble centralis√©e

### 7. Tests de Charge et Ingress

**Probl√©matique :** Valider les performances sous stress et distribuer la charge √©quitablement.

**Solution impl√©ment√©e :** 
- **Ingress NGINX** : Distribution de charge et exposition
- **Tests k6** : G√©n√©ration de charge r√©aliste
- **Corr√©lation m√©triques** : Impact visible dans Grafana

**Configuration cl√© :**
- Ingress avec FQDN `.fbi.com`
- `minikube tunnel` pour LoadBalancer
- Tests k6 via Ingress (pas port-forward)

**Apprentissages :**
- Port-forward sollicite toujours le m√™me pod
- Ingress r√©partit vraiment la charge
- M√©triques temps r√©el essentielles pour le dimensionnement

### 8. Dashboard Personnalis√© pour Application M√©tier

**Probl√©matique :** Suivre les m√©triques sp√©cifiques √† mon application (pas seulement l'infra).

**Solution impl√©ment√©e :** Dashboard custom dans Grafana pour l'endpoint `/info` du guestbook.

**Ce que j'ai d√©couvert :**
- L'endpoint `/info` expose des m√©triques au format Prometheus
- PromQL permet d'extraire et manipuler ces donn√©es
- Les graphiques temporels + jauges donnent une vue compl√®te

**B√©n√©fices :**
- **Monitoring applicatif** : M√©triques business en plus de l'infra
- **Alerting cibl√©** : Notifications sur les KPI critiques
- **Vue unifi√©e** : Infra + app dans le m√™me outil

### 9. Chaos Engineering avec Chaos Mesh

**Probl√©matique :** Tester la r√©silience en conditions r√©elles avant les pannes.

**Solution impl√©ment√©e :** Chaos Mesh pour simuler des pannes contr√¥l√©es (pod-kill).

**Ce que j'ai appris :**
- Chaos Mesh utilise des CRDs pour d√©finir les exp√©riences
- Pod-kill simule les pannes de pods al√©atoires
- L'impact est imm√©diatement visible dans Grafana
- La r√©cup√©ration automatique fonctionne

**B√©n√©fices :**
- **Confiance** : J'ai valid√© la r√©silience avant la prod
- **Am√©lioration continue** : D√©tection des points faibles
- **Monitoring valid√©** : Les alertes se d√©clenchent correctement


---

## ÔøΩ Ce que j'ai retenu

**Erreurs que j'ai √©vit√©es :**
- J'utilise toujours `kubectl delete deployment nom` maintenant (plus jamais juste le nom)
- Je ne touche jamais au service `kubernetes` - j'ai compris que c'est syst√®me
- J'ai m√©moris√© la hi√©rarchie : Cluster ‚Üí Node ‚Üí Namespace ‚Üí Deployment ‚Üí ReplicaSet ‚Üí Pods

**Choix techniques que j'ai faits :**
- J'ai gard√© Docker comme driver minikube - c'est le plus rapide pour le d√©veloppement
- J'ai impl√©ment√© les Topology Spread Constraints partout - c'est obligatoire en production
- J'ai test√© la r√©silience avec `kubectl drain/uncordon` avant chaque d√©ploiement

**Ce qui marche vraiment :**
- J'ai install√© Prometheus + Grafana - l'observabilit√© c'est vital
- J'ai utilis√© k6 avec Ingress pour les tests de charge - √ßa r√©partit vraiment la charge
- J'ai compris la diff√©rence : port-forward = un seul pod, Ingress = distribution √©quitable
- J'ai cr√©√© un dashboard custom pour mon app - les m√©triques business c'est cl√©
- J'ai d√©ploy√© Chaos Mesh - tester la r√©silience avant les vraies pannes
- J'ai install√© un runner GitHub dans mon cluster - CI/CD ma√Ætris√©e
