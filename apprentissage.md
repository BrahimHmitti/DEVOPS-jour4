# üìö Apprentissages DevOps - Jour 4

## üéØ Objectif
Synth√®se des concepts cl√©s et le√ßons apprises sur Kubernetes et la r√©silience applicative.

---

## üéì Concepts Cl√©s Appris

### 1. Architecture Kubernetes
**Hi√©rarchie :** `Cluster ‚Üí Node ‚Üí Namespace ‚Üí Deployment ‚Üí ReplicaSet ‚Üí Pods`

**Points cl√©s :**
- Un cluster contient plusieurs n≈ìuds (machines physiques/virtuelles)
- Les namespaces isolent logiquement les ressources
- Les deployments g√®rent automatiquement les ReplicaSets et les pods

### 2. Gestion des Ressources
**Le√ßons importantes :**
- Toujours sp√©cifier le type de ressource : `kubectl delete deployment nom` (pas juste `nom`)
- Le service `kubernetes` (ClusterIP: 10.96.0.1) est syst√®me et ne doit jamais √™tre supprim√©
- Utiliser les labels pour g√©rer plusieurs ressources : `kubectl delete all -l app=monapp`

### 3. Architecture R√©seau
**Organisation du r√©seau :**
- **Pods** : R√©seau `10.244.x.x`
- **N≈ìuds** : R√©seau `192.168.49.x` (minikube)
- **Control Plane** : Composants ma√Ætres (API, etcd, scheduler)
- **Worker Nodes** : Composants de travail (kubelet, kube-proxy)

### 4. Drivers Minikube
**Choix automatique optimal :**
- **Docker** : Rapide, conteneurs, optimal pour d√©veloppement local WSL/Ubuntu
- **VirtualBox** : Plus lent, VMs compl√®tes, pour tests avanc√©s
- **Hyper-V** : Moyen, pour Windows Pro/Enterprise

### 5. Topology Spread Constraints - R√©silience Applicative

**Probl√©matique :** √âviter qu'une panne d'un n≈ìud affecte toute l'application (SPOF - Single Point of Failure).

**Solution impl√©ment√©e :** Configuration de contraintes de r√©partition topologique.

**Configuration essentielle :**
```yaml
topologySpreadConstraints:
- maxSkew: 1                              # Max 1 pod de diff√©rence entre n≈ìuds
  topologyKey: kubernetes.io/hostname     # R√©partition par n≈ìud
  whenUnsatisfiable: DoNotSchedule        # Contrainte stricte
  labelSelector:
    matchLabels:
      app: resilient-app
```

**Modes de contraintes :**
- **`DoNotSchedule`** : Strict - pr√©f√®re la r√©silience (pods en Pending si n√©cessaire)
- **`ScheduleAnyway`** : Souple - pr√©f√®re la disponibilit√© (schedules quand m√™me)

**B√©n√©fices :**
- **Haute disponibilit√©** : 50% de l'app reste op√©rationnelle si un n≈ìud tombe
- **Distribution √©quitable** : √âvite la surcharge d'un seul n≈ìud
- **Production-ready** : Respecte les bonnes pratiques DevOps

---

## ‚úÖ Validation - Monitoring et Tests de Charge

### üéØ Stack Prometheus D√©ploy√©e et Valid√©e

**Infrastructure monitoring :** Prometheus + Grafana + AlertManager op√©rationnels

**Validations r√©ussies :**
1. ‚úÖ **Repository Helm ajout√©** : prometheus-community accessible
2. ‚úÖ **Stack d√©ploy√©e** : Tous les composants fonctionnels
3. ‚úÖ **Dashboards Kubernetes** : M√©triques cluster visibles
4. ‚úÖ **Interface Grafana** : Acc√®s via port-forward

### üéØ Tests de Charge k6 Valid√©s

**Infrastructure r√©seau :** Ingress NGINX + minikube tunnel

**Validations r√©ussies :**
1. ‚úÖ **Addon ingress activ√©** : NGINX controller d√©ploy√©
2. ‚úÖ **Ingress configur√©** : FQDN `.fbi.com` fonctionnel
3. ‚úÖ **Tests k6 adapt√©s** : Charge distribu√©e via Ingress
4. ‚úÖ **M√©triques observ√©es** : Impact visible en temps r√©el dans Grafana

**R√©sultat final :** J'ai maintenant un monitoring complet et des tests de performance valid√©s.

---

## ‚úÖ Validation - Topology Spread Constraints

### üéØ Configuration Test√©e et Valid√©e

**Infrastructure :** Cluster minikube 2 n≈ìuds + 4 pods nginx

**Tests de r√©silience r√©ussis :**
1. ‚úÖ **R√©partition √©quitable** : 2 pods par n≈ìud initialement
2. ‚úÖ **Simulation panne** : `kubectl drain` ‚Üí Pods √©vacu√©s, contraintes respect√©es
3. ‚úÖ **Remise en service** : `kubectl uncordon` ‚Üí Redistribution automatique
4. ‚úÖ **Application op√©rationnelle** : Service accessible pendant tous les tests

**R√©sultat final :** L'application est maintenant parfaitement r√©siliente aux pannes de n≈ìuds.

### 6. Stack de Monitoring Prometheus/Grafana

**Probl√©matique :** Besoin de surveiller les m√©triques du cluster et des applications en temps r√©el.

**Solution d√©ploy√©e :** Stack kube-prometheus-stack avec Helm.

**Composants install√©s :**
- **Prometheus** : Collecte et stockage des m√©triques
- **Grafana** : Dashboards et visualisation
- **AlertManager** : Gestion des alertes

**B√©n√©fices :**
- **Observabilit√© compl√®te** : M√©triques cluster + applications
- **Dashboards pr√©-configur√©s** : Kubernetes, n≈ìuds, pods, services
- **Alerting** : Notifications automatiques en cas d'anomalie
- **Interface unified** : Vue d'ensemble centralis√©e

### 7. Tests de Charge et Ingress

**Probl√©matique :** Valider les performances sous stress et distribuer la charge √©quitablement.

**Solution impl√©ment√©e :** 
- **Ingress NGINX** : Distribution de charge et exposition
- **Tests k6** : G√©n√©ration de charge r√©aliste
- **Corr√©lation m√©triques** : Impact visible dans Grafana

**Configuration cl√© :**
- Ingress avec FQDN `.fbi.com`
- `minikube tunnel` pour LoadBalancer
- Tests k6 via Ingress (pas port-forward)

**Apprentissages :**
- Port-forward sollicite toujours le m√™me pod
- Ingress r√©partit vraiment la charge
- M√©triques temps r√©el essentielles pour le dimensionnement

---

## ÔøΩ Ce que j'ai retenu

**Erreurs que j'ai √©vit√©es :**
- J'utilise toujours `kubectl delete deployment nom` maintenant (plus jamais juste le nom)
- Je ne touche jamais au service `kubernetes` - j'ai compris que c'est syst√®me
- J'ai m√©moris√© la hi√©rarchie : Cluster ‚Üí Node ‚Üí Namespace ‚Üí Deployment ‚Üí ReplicaSet ‚Üí Pods

**Choix techniques que j'ai faits :**
- J'ai gard√© Docker comme driver minikube - c'est le plus rapide pour le d√©veloppement
- J'ai impl√©ment√© les Topology Spread Constraints partout - c'est obligatoire en production
- J'ai test√© la r√©silience avec `kubectl drain/uncordon` avant chaque d√©ploiement

**Ce qui marche vraiment :**
- J'ai install√© Prometheus + Grafana - l'observabilit√© c'est vital
- J'ai utilis√© k6 avec Ingress pour les tests de charge - √ßa r√©partit vraiment la charge
- J'ai compris la diff√©rence : port-forward = un seul pod, Ingress = distribution √©quitable
