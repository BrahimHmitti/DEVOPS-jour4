# üìö Apprentissages DevOps - Jour 4

## üéØ Objectif
Synth√®se des concepts cl√©s et le√ßons apprises sur Kubernetes et la r√©silience applicative.

---

## üéì Concepts Cl√©s Appris

### 1. Architecture Kubernetes
**Hi√©rarchie :** `Cluster ‚Üí Node ‚Üí Namespace ‚Üí Deployment ‚Üí ReplicaSet ‚Üí Pods`

**Points cl√©s :**
- Un cluster contient plusieurs n≈ìuds (machines physiques/virtuelles)
- Les namespaces isolent logiquement les ressources
- Les deployments g√®rent automatiquement les ReplicaSets et les pods

### 2. Gestion des Ressources
**Le√ßons importantes :**
- Toujours sp√©cifier le type de ressource : `kubectl delete deployment nom` (pas juste `nom`)
- Le service `kubernetes` (ClusterIP: 10.96.0.1) est syst√®me et ne doit jamais √™tre supprim√©
- Utiliser les labels pour g√©rer plusieurs ressources : `kubectl delete all -l app=monapp`

### 3. Architecture R√©seau
**Organisation du r√©seau :**
- **Pods** : R√©seau `10.244.x.x`
- **N≈ìuds** : R√©seau `192.168.49.x` (minikube)
- **Control Plane** : Composants ma√Ætres (API, etcd, scheduler)
- **Worker Nodes** : Composants de travail (kubelet, kube-proxy)

### 4. Drivers Minikube
**Choix automatique optimal :**
- **Docker** : Rapide, conteneurs, optimal pour d√©veloppement local WSL/Ubuntu
- **VirtualBox** : Plus lent, VMs compl√®tes, pour tests avanc√©s
- **Hyper-V** : Moyen, pour Windows Pro/Enterprise

### 5. Topology Spread Constraints - R√©silience Applicative

**Probl√©matique :** √âviter qu'une panne d'un n≈ìud affecte toute l'application (SPOF - Single Point of Failure).

**Solution impl√©ment√©e :** Configuration de contraintes de r√©partition topologique.

**Configuration essentielle :**
```yaml
topologySpreadConstraints:
- maxSkew: 1                              # Max 1 pod de diff√©rence entre n≈ìuds
  topologyKey: kubernetes.io/hostname     # R√©partition par n≈ìud
  whenUnsatisfiable: DoNotSchedule        # Contrainte stricte
  labelSelector:
    matchLabels:
      app: resilient-app
```

**Modes de contraintes :**
- **`DoNotSchedule`** : Strict - pr√©f√®re la r√©silience (pods en Pending si n√©cessaire)
- **`ScheduleAnyway`** : Souple - pr√©f√®re la disponibilit√© (schedules quand m√™me)

**B√©n√©fices :**
- **Haute disponibilit√©** : 50% de l'app reste op√©rationnelle si un n≈ìud tombe
- **Distribution √©quitable** : √âvite la surcharge d'un seul n≈ìud
- **Production-ready** : Respecte les bonnes pratiques DevOps

---

## ‚úÖ Validation - Monitoring et Tests de Charge

### üéØ Stack Prometheus D√©ploy√©e et Valid√©e

**Infrastructure monitoring :** Prometheus + Grafana + AlertManager op√©rationnels

**Validations r√©ussies :**
1. ‚úÖ **Repository Helm ajout√©** : prometheus-community accessible
2. ‚úÖ **Stack d√©ploy√©e** : Tous les composants fonctionnels
3. ‚úÖ **Dashboards Kubernetes** : M√©triques cluster visibles
4. ‚úÖ **Interface Grafana** : Acc√®s via port-forward

### üéØ Tests de Charge k6 Valid√©s

**Infrastructure r√©seau :** Ingress NGINX + minikube tunnel

**Validations r√©ussies :**
1. ‚úÖ **Addon ingress activ√©** : NGINX controller d√©ploy√©
2. ‚úÖ **Ingress configur√©** : FQDN `.fbi.com` fonctionnel
3. ‚úÖ **Tests k6 adapt√©s** : Charge distribu√©e via Ingress
4. ‚úÖ **M√©triques observ√©es** : Impact visible en temps r√©el dans Grafana

### üéØ Dashboard Custom et Chaos Engineering Valid√©s

**Monitoring applicatif :** Dashboard guestbook `/info` + alerting

**Validations r√©ussies :**
1. ‚úÖ **Endpoint `/info` explor√©** : M√©triques custom identifi√©es
2. ‚úÖ **Dashboard cr√©√©** : Panels PromQL fonctionnels
3. ‚úÖ **Alertes configur√©es** : Notifications sur KPI critiques
4. ‚úÖ **Chaos Mesh d√©ploy√©** : Exp√©riences pod-kill op√©rationnelles
5. ‚úÖ **R√©silience valid√©e** : R√©cup√©ration automatique confirm√©e

### üéØ CI/CD Self-Hosted Valid√©

**Infrastructure CI/CD :** GitHub Actions runner dans Kubernetes

**Validations r√©ussies :**
1. ‚úÖ **Token GitHub cr√©√©** : Secret Kubernetes configur√©
2. ‚úÖ **Runner d√©ploy√©** : Pod fonctionnel dans le cluster
3. ‚úÖ **Enregistrement automatique** : Visible dans GitHub settings
4. ‚úÖ **Workflow test√©** : Ex√©cution r√©ussie

**R√©sultat final :** J'ai maintenant un environnement DevOps complet : monitoring + chaos engineering + CI/CD.

---

## ‚úÖ Validation - Topology Spread Constraints

### üéØ Configuration Test√©e et Valid√©e

**Infrastructure :** Cluster minikube 2 n≈ìuds + 4 pods nginx

**Tests de r√©silience r√©ussis :**
1. ‚úÖ **R√©partition √©quitable** : 2 pods par n≈ìud initialement
2. ‚úÖ **Simulation panne** : `kubectl drain` ‚Üí Pods √©vacu√©s, contraintes respect√©es
3. ‚úÖ **Remise en service** : `kubectl uncordon` ‚Üí Redistribution automatique
4. ‚úÖ **Application op√©rationnelle** : Service accessible pendant tous les tests

**R√©sultat final :** L'application est maintenant parfaitement r√©siliente aux pannes de n≈ìuds.

### 6. Stack de Monitoring Prometheus/Grafana

**Probl√©matique :** Besoin de surveiller les m√©triques du cluster et des applications en temps r√©el.

**Solution d√©ploy√©e :** Stack kube-prometheus-stack avec Helm.

**Composants install√©s :**
- **Prometheus** : Collecte et stockage des m√©triques
- **Grafana** : Dashboards et visualisation
- **AlertManager** : Gestion des alertes

**B√©n√©fices :**
- **Observabilit√© compl√®te** : M√©triques cluster + applications
- **Dashboards pr√©-configur√©s** : Kubernetes, n≈ìuds, pods, services
- **Alerting** : Notifications automatiques en cas d'anomalie
- **Interface unified** : Vue d'ensemble centralis√©e

### 7. Tests de Charge et Ingress

**Probl√©matique :** Valider les performances sous stress et distribuer la charge √©quitablement.

**Solution impl√©ment√©e :** 
- **Ingress NGINX** : Distribution de charge et exposition
- **Tests k6** : G√©n√©ration de charge r√©aliste
- **Corr√©lation m√©triques** : Impact visible dans Grafana

**Configuration cl√© :**
- Ingress avec FQDN `.fbi.com`
- `minikube tunnel` pour LoadBalancer
- Tests k6 via Ingress (pas port-forward)

**Apprentissages :**
- Port-forward sollicite toujours le m√™me pod
- Ingress r√©partit vraiment la charge
- M√©triques temps r√©el essentielles pour le dimensionnement

### 8. Dashboard Personnalis√© pour Application M√©tier

**Probl√©matique :** Suivre les m√©triques sp√©cifiques √† mon application (pas seulement l'infra).

**Solution impl√©ment√©e :** Dashboard custom dans Grafana pour l'endpoint `/info` du guestbook.

**Ce que j'ai d√©couvert :**
- L'endpoint `/info` expose des m√©triques au format Prometheus
- PromQL permet d'extraire et manipuler ces donn√©es
- Les graphiques temporels + jauges donnent une vue compl√®te

**B√©n√©fices :**
- **Monitoring applicatif** : M√©triques business en plus de l'infra
- **Alerting cibl√©** : Notifications sur les KPI critiques
- **Vue unifi√©e** : Infra + app dans le m√™me outil

### 9. Chaos Engineering avec Chaos Mesh

**Probl√©matique :** Tester la r√©silience en conditions r√©elles avant les pannes.

**Solution impl√©ment√©e :** Chaos Mesh pour simuler des pannes contr√¥l√©es (pod-kill).

**Ce que j'ai appris :**
- Chaos Mesh utilise des CRDs pour d√©finir les exp√©riences
- Pod-kill simule les pannes de pods al√©atoires
- L'impact est imm√©diatement visible dans Grafana
- La r√©cup√©ration automatique fonctionne

**B√©n√©fices :**
- **Confiance** : J'ai valid√© la r√©silience avant la prod
- **Am√©lioration continue** : D√©tection des points faibles
- **Monitoring valid√©** : Les alertes se d√©clenchent correctement

### 10. GitHub Actions Runner Self-Hosted

**Probl√©matique :** Ex√©cuter les CI/CD dans mon infrastructure (contr√¥le + s√©curit√©).

**Solution impl√©ment√©e :** Runner GitHub d√©ploy√© comme pod dans Kubernetes.

**Configuration r√©alis√©e :**
- Token GitHub stock√© comme secret Kubernetes
- Image officielle du runner GitHub Actions
- Acc√®s Docker pour build des images

**B√©n√©fices :**
- **Contr√¥le total** : Runner dans mon cluster
- **S√©curit√©** : Pas d'exposition externe
- **Int√©gration** : Acc√®s direct aux ressources Kubernetes

---

## ÔøΩ Ce que j'ai retenu

**Erreurs que j'ai √©vit√©es :**
- J'utilise toujours `kubectl delete deployment nom` maintenant (plus jamais juste le nom)
- Je ne touche jamais au service `kubernetes` - j'ai compris que c'est syst√®me
- J'ai m√©moris√© la hi√©rarchie : Cluster ‚Üí Node ‚Üí Namespace ‚Üí Deployment ‚Üí ReplicaSet ‚Üí Pods

**Choix techniques que j'ai faits :**
- J'ai gard√© Docker comme driver minikube - c'est le plus rapide pour le d√©veloppement
- J'ai impl√©ment√© les Topology Spread Constraints partout - c'est obligatoire en production
- J'ai test√© la r√©silience avec `kubectl drain/uncordon` avant chaque d√©ploiement

**Ce qui marche vraiment :**
- J'ai install√© Prometheus + Grafana - l'observabilit√© c'est vital
- J'ai utilis√© k6 avec Ingress pour les tests de charge - √ßa r√©partit vraiment la charge
- J'ai compris la diff√©rence : port-forward = un seul pod, Ingress = distribution √©quitable
- J'ai cr√©√© un dashboard custom pour mon app - les m√©triques business c'est cl√©
- J'ai d√©ploy√© Chaos Mesh - tester la r√©silience avant les vraies pannes
- J'ai install√© un runner GitHub dans mon cluster - CI/CD ma√Ætris√©e
