# ğŸ“š Apprentissages DevOps - Jour 4

> ğŸ“ **TP Complet** : Infrastructure rÃ©siliente, Monitoring, Chaos Engineering, CI/CD et GitOps


---

# ğŸ”· CE QUE J'AI APPRIS ET RÃ‰ALISÃ‰

## PARTIE 0 : Architecture Multi-Nodes Kubernetes

J'ai crÃ©Ã© un cluster minikube avec 2 nÅ“uds pour simuler un environnement de production rÃ©el. J'ai compris que la multi-node architecture est essentielle pour tester la rÃ©silience des applications. C'est la base de tout ce que j'ai fait aprÃ¨s.

**Commande utilisÃ©e :**
```bash
minikube start --nodes 2 --driver=docker --cpus=2 --memory=3500
```

**Ce que j'ai retenu :** Un seul nÅ“ud ne suffit jamais pour tester la haute disponibilitÃ©. J'ai appris Ã  vÃ©rifier la santÃ© des nÅ“uds avec `kubectl get nodes` et Ã  comprendre les rÃ´les control-plane vs worker.

---

## PARTIE 1 : Topology Spread Constraints

J'ai dÃ©couvert un mÃ©canisme hyper puissant pour distribuer les pods intelligemment. Les Topology Spread Constraints permettent de s'assurer qu'une application ne se retrouve pas entiÃ¨rement sur un seul nÅ“ud.

**Fichier crÃ©Ã© :** `resilient-app-deployment.yaml`

**Configuration clÃ© :**
```yaml
topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: kubernetes.io/hostname
    whenUnsatisfiable: DoNotSchedule
```

**Test de rÃ©silience effectuÃ© :** J'ai drainÃ© un nÅ“ud avec `kubectl drain` et j'ai vu les pods se redistribuer automatiquement. C'Ã©tait impressionnant de voir Kubernetes respecter les contraintes mÃªme pendant une panne simulÃ©e.

**LeÃ§on importante :** `whenUnsatisfiable: DoNotSchedule` crÃ©e des pods Pending si la contrainte ne peut pas Ãªtre respectÃ©e. C'est voulu - mieux vaut attendre que de violer la rÃ¨gle de distribution.

---

## PARTIE 2 : Prometheus et Grafana

J'ai dÃ©ployÃ© toute une stack de monitoring via Helm. Ã‡a m'a ouvert les yeux sur l'importance de l'observabilitÃ©. Sans mÃ©triques, on est aveugle.

**Installation via Helm :**
```bash
helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack -n monitoring
```

**Ce que j'ai appris :**
- Prometheus scrape automatiquement les mÃ©triques des pods avec des annotations
- Grafana vient avec des dashboards prÃ©-configurÃ©s pour Kubernetes
- AlertManager permet de configurer des alertes (Slack, email, etc.)

**Mot de passe Grafana :** Le secret s'appelle `kube-prometheus-stack-grafana` et contient le mot de passe en base64.

**Retour d'expÃ©rience :** Le dÃ©ploiement prend 5-10 minutes avec beaucoup de CRDs (ServiceMonitor, PrometheusRule, etc.). Il faut Ãªtre patient et ne pas paniquer devant les warnings Helm.

---

## PARTIE 3 : Ingress NGINX et Load Testing

J'ai configurÃ© l'Ingress pour exposer mon application avec un nom de domaine. Ensuite j'ai fait des tests de charge pour voir comment elle rÃ©agit.

**Fichiers crÃ©Ã©s :**
- `guestbook-ingress.yaml` - Configuration Ingress avec host `guestbook.fbi.com`
- `load-test.js` - Script k6 pour bombarder l'application

**Point important :** `minikube tunnel` est nÃ©cessaire pour que l'Ingress obtienne une IP externe. Sans Ã§a, pas d'accÃ¨s depuis l'extÃ©rieur du cluster.

**Test de charge :** J'ai envoyÃ© 100+ requÃªtes avec k6 et curl. J'ai vu dans Grafana les requÃªtes se rÃ©partir sur les 3 replicas du deployment. La distribution Ã©tait parfaite.

**Ce que j'ai compris :** L'Ingress fait du load balancing automatique entre les pods du Service. Pas besoin de configuration supplÃ©mentaire.

---

## PARTIE 4 : Dashboard Grafana PersonnalisÃ©

J'ai crÃ©Ã© une application qui expose ses propres mÃ©triques au format Prometheus. Ã‡a m'a fait comprendre comment instrumenter du code.

**Fichier crÃ©Ã© :** `guestbook-with-metrics.yaml`

**Endpoint /info :**
```
# TYPE http_requests_total counter
http_requests_total{method="GET",status="200"} 12345
# TYPE app_active_users gauge
app_active_users 42
```

**Annotation importante pour Prometheus :**
```yaml
annotations:
  prometheus.io/scrape: "true"
  prometheus.io/port: "80"
  prometheus.io/path: "/info"
```

**LeÃ§on :** Prometheus dÃ©couvre automatiquement les endpoints grÃ¢ce aux annotations. Dans Grafana, j'ai pu crÃ©er un dashboard custom avec ces mÃ©triques. C'est puissant pour monitorer des mÃ©triques business (utilisateurs actifs, transactions, etc.).

---

## PARTIE 5 : Chaos Engineering avec Chaos Mesh

LÃ , Ã§a devient sÃ©rieux. J'ai installÃ© Chaos Mesh pour casser volontairement des pods et tester si l'application survit.

**Installation :**
```bash
helm install chaos-mesh chaos-mesh/chaos-mesh -n chaos-mesh --create-namespace
```

**ExpÃ©rience crÃ©Ã©e :** `chaos-pod-kill-experiment.yaml`

Cette expÃ©rience tue un pod guestbook toutes les 2 minutes pendant 30 secondes. Le but ? VÃ©rifier que l'application reste accessible malgrÃ© les pannes.

**RÃ©sultat :** GrÃ¢ce aux 3 replicas et Ã  l'Ingress, l'application n'a jamais Ã©tÃ© down. Les requÃªtes Ã©taient routÃ©es vers les pods survivants. La magie de Kubernetes !

**Ce que j'ai appris :** Le Chaos Engineering n'est pas une destruction gratuite. C'est une mÃ©thode scientifique pour valider la rÃ©silience. Chaos Mesh offre plein de types d'expÃ©riences : network delay, IO errors, stress CPU, etc.

---

## PARTIE 6 : GitHub Runner Self-Hosted

J'ai dÃ©ployÃ© un runner GitHub Actions directement dans mon cluster Kubernetes. Ã‡a permet d'exÃ©cuter les pipelines CI/CD dans mon propre environnement.

**Fichier crÃ©Ã© :** `github-runner-deployment.yaml`

### âŒ **ERREUR IMPORTANTE - Apprentissage sur le choix d'image**

**ProblÃ¨me rencontrÃ© :**
J'ai initialement utilisÃ© l'image `myoung34/github-runner:latest` pensant que c'Ã©tait la bonne solution. Mais :
1. âŒ Cette image n'est **PAS officielle** - c'est une image communautaire
2. âŒ Elle est **trÃ¨s volumineuse** (~1.5GB) et prend 15+ minutes Ã  tÃ©lÃ©charger
3. âŒ Les consignes demandent d'utiliser "l'image officielle du runner GitHub Actions"
4. âŒ Le pod crashait en **CrashLoopBackOff** avec erreur `401` (token expirÃ©)

**Pourquoi cette erreur :**
- Les consignes ne spÃ©cifient pas exactement quelle image utiliser
- J'ai pris une image populaire sans vÃ©rifier qu'elle Ã©tait officielle
- Je n'ai pas suivi les instructions officielles de GitHub qui demandent de tÃ©lÃ©charger le binaire

**Solution correcte selon GitHub :**
```bash
# TÃ©lÃ©charger le runner officiel
curl -o actions-runner-linux-x64-2.328.0.tar.gz -L \
  https://github.com/actions/runner/releases/download/v2.328.0/actions-runner-linux-x64-2.328.0.tar.gz
# Configurer
./config.sh --url https://github.com/BrahimHmitti/DEVOPS-jour4 --token TOKEN
# Lancer
./run.sh
```

**Nouveau savoir :**
- âœ… Toujours vÃ©rifier la source officielle avant d'utiliser une image Docker
- âœ… "Populaire" â‰  "Officiel" - myoung34/github-runner a 10M+ downloads mais n'est pas officiel
- âœ… GitHub ne fournit pas d'image Docker ready-to-use - il faut crÃ©er son propre Dockerfile
- âœ… Les tokens GitHub Runner **expirent aprÃ¨s 1h** - il faut en gÃ©nÃ©rer un nouveau Ã  chaque dÃ©ploiement

**Pourquoi c'est utile :**
Comprendre qu'il faut parfois crÃ©er ses propres images plutÃ´t que de chercher une solution toute faite. Cela donne plus de contrÃ´le et Ã©vite les dÃ©pendances externes non maintenues.

**Avantages du runner self-hosted :**
- Pas de limite de minutes CI/CD (gratuit)
- AccÃ¨s direct au cluster Kubernetes
- PossibilitÃ© d'utiliser des images Docker custom
- ContrÃ´le total sur l'environnement d'exÃ©cution

**Configuration correcte :** 
- âœ… Token stockÃ© via `kubectl create secret` (PAS dans le YAML)
- âœ… Token Ã  rÃ©gÃ©nÃ©rer sur GitHub Settings > Actions > Runners > New
- âš ï¸ Le token expire aprÃ¨s 1h selon les consignes

**Point d'attention :** J'ai montÃ© `/var/run/docker.sock` pour permettre au runner de builder des images Docker. C'est puissant mais Ã§a donne beaucoup de privilÃ¨ges.

---

## PARTIE 7 : Pipeline CI/CD GitHub Actions

J'ai crÃ©Ã© un workflow complet qui build, scan et push des images Docker automatiquement Ã  chaque commit.

**Fichier crÃ©Ã© :** `.github/workflows/docker-build.yaml`

**Ã‰tapes du pipeline :**
1. **Checkout** du code
2. **Build Docker** avec BuildKit et cache
3. **Push** vers Docker Hub (tags `latest` + SHA)
4. **Scan Trivy** pour dÃ©tecter les vulnÃ©rabilitÃ©s
5. **Upload** des rÃ©sultats vers GitHub Security

**Ce que j'ai adorÃ© :** Le scan Trivy dÃ©tecte automatiquement les CVE dans l'image. Les rÃ©sultats apparaissent dans l'onglet Security de GitHub. C'est du DevSecOps !

**Secrets configurÃ©s :**
- `DOCKER_USERNAME` : Mon username Docker Hub
- `DOCKER_PASSWORD` : Token d'accÃ¨s Docker Hub

**LeÃ§on :** Jamais de credentials en dur dans le code. Toujours utiliser les secrets GitHub/Kubernetes.

---

## PARTIE 8 : Renovate Bot

J'ai dÃ©ployÃ© Renovate pour automatiser les mises Ã  jour de dÃ©pendances. Plus besoin de surveiller manuellement les nouvelles versions.

**Fichier crÃ©Ã© :** `renovate-deployment.yaml`

**Configuration :** CronJob qui s'exÃ©cute tous les jours Ã  2h du matin. Il scanne le repo et crÃ©e des Pull Requests pour :
- Mettre Ã  jour les images Docker dans les YAML
- Updater les versions de Helm charts
- Proposer les nouvelles versions de dÃ©pendances

**Automerge :** J'ai configurÃ© l'automerge pour les mises Ã  jour minor/patch. Les mises Ã  jour major nÃ©cessitent une review humaine (breaking changes possibles).

**Ce que Ã§a m'apporte :** SÃ©curitÃ© (patches de vulnÃ©rabilitÃ©s) + Maintenance continue sans effort. C'est un vrai gain de temps.

---

## PARTIE 9 : ArgoCD GitOps

ArgoCD, c'est le saint Graal du GitOps. L'Ã©tat dÃ©sirÃ© est dans Git, ArgoCD synchronise automatiquement le cluster.

**Installation :**
```bash
kubectl apply -n argocd -f https://raw.githubusercontent.com/argoproj/argo-cd/stable/manifests/install.yaml
```

**Fichier crÃ©Ã© :** `argocd-application.yaml`

**Principe GitOps que j'ai appliquÃ© :**
1. Tous mes manifests sont dans le dossier `manifests/` du repo GitHub
2. ArgoCD surveille ce dossier
3. Chaque commit dÃ©clenche une synchronisation automatique
4. Si je modifie manuellement le cluster, ArgoCD le dÃ©tecte et peut auto-heal

**Configuration clÃ© :**
```yaml
syncPolicy:
  automated:
    prune: true      # Supprime les ressources si elles sont retirÃ©es de Git
    selfHeal: true   # Corrige les drifts automatiquement
```

**UI ArgoCD :** L'interface graphique est magnifique. Je vois l'Ã©tat de santÃ© de chaque ressource, l'historique des sync, les diffs Gitâ†’Cluster.

**Ce que j'ai compris :** Git devient la source de vÃ©ritÃ© unique. Plus de `kubectl apply` manuel. Tout passe par un commit. C'est auditable, versionnÃ©, rollbackable.

---

## PARTIE 10 : Burrito (Infrastructure as Code) 

Burrito est un opÃ©rateur Kubernetes qui exÃ©cute du Terraform/OpenTofu directement dans le cluster. C'est du IaC as a Service.

**Fichiers crÃ©Ã©s :**
- `burrito-deployment.yaml` - OpÃ©rateur Burrito
- `burrito-terraformlayer.yaml` - CRD TerraformLayer

**Use case :** GÃ©rer des ressources cloud (AWS, GCP, Azure) depuis Kubernetes avec Terraform, mais en mode dÃ©claratif Kubernetes.

**Ce que j'ai trouvÃ© gÃ©nial :** Le state Terraform est stockÃ© dans un Secret Kubernetes. Les plans Terraform s'exÃ©cutent dans des Jobs. Tout est orchestrÃ© par l'opÃ©rateur.

**Limite :** C'est un projet rÃ©cent, moins mature qu'Atlantis ou Terraform Cloud. Mais l'approche est innovante.

---

## PARTIE 11 : Signature d'Images avec Cosign

Cosign permet de signer cryptographiquement les images Docker pour garantir leur authenticitÃ©.

**Installation de Cosign :**
```bash
# TÃ©lÃ©charger depuis https://github.com/sigstore/cosign
cosign generate-key-pair
```

**Signature d'une image :**
```bash
cosign sign --key cosign.key docker.io/username/guestbook:v1.0
```

**VÃ©rification :**
```bash
cosign verify --key cosign.pub docker.io/username/guestbook:v1.0
```

**Ce que Ã§a protÃ¨ge :** Supply chain attacks. On s'assure que l'image n'a pas Ã©tÃ© modifiÃ©e entre le build et le dÃ©ploiement. Sigstore est la nouvelle norme de l'industrie.

**IntÃ©gration :** J'ai ajoutÃ© la signature dans le pipeline CI/CD aprÃ¨s le push Docker Hub.

---

## PARTIE 12 : VÃ©rification des Signatures 

J'ai configurÃ© Kyverno (admission controller) pour bloquer le dÃ©ploiement d'images non signÃ©es.

**Installation Kyverno :**
```bash
helm install kyverno kyverno/kyverno -n kyverno --create-namespace
```

**Policy crÃ©Ã©e :**
```yaml
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: verify-image-signature
spec:
  rules:
  - name: check-signature
    match:
      resources:
        kinds:
        - Pod
    verifyImages:
    - image: "docker.io/username/*"
      key: |-
        -----BEGIN PUBLIC KEY-----
        ...
        -----END PUBLIC KEY-----
```

**RÃ©sultat :** Si quelqu'un essaie de dÃ©ployer une image non signÃ©e, Kyverno la rejette. Kubernetes devient une forteresse.

**Ce que j'ai appris :** La sÃ©curitÃ© doit Ãªtre enforcÃ©e automatiquement, pas par des processus manuels. L'admission control est le bon endroit pour Ã§a.

---

## PARTIE 13 : Documentation Finale

J'ai crÃ©Ã© plusieurs documents pour capitaliser mes apprentissages :

**Fichiers crÃ©Ã©s :**
- `apprentissage.md` (ce fichier) - Mes notes personnelles sur tout le TP
- `RECAP.md` - RÃ©capitulatif technique des 13 parties
- `STATUS.md` - Ã‰tat dÃ©taillÃ© de chaque partie avec commandes
- `README.md` - Guide de dÃ©marrage rapide

**Scripts utilitaires :**
- `test-all-tp.sh` - Script de validation automatique des 13 parties
- `quick-commands.sh` - Menu interactif pour dÃ©ployer/tester chaque partie
- `deploy-full-tp.sh` - DÃ©ploiement automatisÃ© complet

**Diagramme d'architecture :** J'ai crÃ©Ã© un schÃ©ma mental de l'infrastructure complÃ¨te :

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     CLUSTER KUBERNETES                      â”‚
â”‚                     (2 Nodes Minikube)                      â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚   Node 1         â”‚  â”‚   Node 2         â”‚               â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚               â”‚
â”‚  â”‚  â”‚ Resilient  â”‚  â”‚  â”‚  â”‚ Resilient  â”‚  â”‚               â”‚
â”‚  â”‚  â”‚ App (2)    â”‚  â”‚  â”‚  â”‚ App (2)    â”‚  â”‚  <- Topology  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚     Spread    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚               â”‚
â”‚  â”‚  â”‚ Guestbook  â”‚  â”‚  â”‚  â”‚ Guestbook  â”‚  â”‚               â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ INGRESS NGINX â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  guestbook.fbi.com â†’ Load Balancing                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ NAMESPACE: monitoring â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”‚
â”‚  â”‚  Prometheus + Grafana + AlertManager        â”‚          â”‚
â”‚  â”‚  ServiceMonitors â†’ Scraping automatique     â”‚          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ NAMESPACE: chaos-mesh â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  Chaos Controller + Dashboard                â”‚         â”‚
â”‚  â”‚  PodChaos: kill 1 pod / 2 min               â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ NAMESPACE: argocd â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
â”‚  â”‚  ArgoCD Server + Repo Server + Controller    â”‚        â”‚
â”‚  â”‚  GitOps: GitHub â†’ Cluster (sync auto)       â”‚        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   GITHUB ACTIONS      â”‚
              â”‚   (Runner in-cluster) â”‚
              â”‚   Build â†’ Trivy â†’ Pushâ”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ Docker Hub  â”‚
                  â”‚ (Images)    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸ“ COMPÃ‰TENCES ACQUISES

## Techniques
- âœ… Configuration cluster Kubernetes multi-nodes
- âœ… MaÃ®trise des Topology Spread Constraints
- âœ… DÃ©ploiement stack Prometheus/Grafana via Helm
- âœ… Configuration Ingress NGINX avec routing
- âœ… Instrumentation applicative (mÃ©triques Prometheus)
- âœ… Chaos Engineering avec Chaos Mesh
- âœ… CI/CD avec GitHub Actions et runners self-hosted
- âœ… GitOps avec ArgoCD (automated sync + self-heal)
- âœ… Automatisation des mises Ã  jour avec Renovate
- âœ… Infrastructure as Code avec Burrito/Terraform
- âœ… Signature et vÃ©rification d'images Docker (Cosign)
- âœ… Admission control avec Kyverno

## MÃ©thodologiques
- **Test-Driven Infrastructure** : J'ai appris Ã  tester systÃ©matiquement chaque composant
- **ObservabilitÃ© First** : DÃ©ployer le monitoring AVANT l'application
- **Chaos Engineering** : Casser pour valider la rÃ©silience
- **GitOps** : Git comme source de vÃ©ritÃ© unique
- **Security by Design** : Signatures d'images, scan de vulnÃ©rabilitÃ©s

## Soft Skills
- **Patience** : Certains dÃ©ploiements prennent 10 minutes (Prometheus, ArgoCD)
- **Debug systÃ©matique** : `kubectl logs`, `kubectl describe`, `kubectl get events`
- **Documentation** : Ã‰crire pendant qu'on fait, pas aprÃ¨s
- **Automatisation** : Si je le fais 2 fois, j'en fais un script

---

# ğŸš€ CE QUI M'A LE PLUS MARQUÃ‰

## 1. La puissance du GitOps
Avoir Git comme source de vÃ©ritÃ© change TOUT. Plus de config manuelle, plus de "Ã§a marche sur ma machine". Un commit = un dÃ©ploiement. Un revert = un rollback. C'est tellement Ã©lÃ©gant.

## 2. L'importance de l'observabilitÃ©
Sans Prometheus/Grafana, je n'aurais jamais vu la rÃ©partition des requÃªtes, l'impact du pod-kill, les mÃ©triques custom. L'observabilitÃ© n'est pas optionnelle, elle est fondamentale.

## 3. Le Chaos Engineering n'est pas destructif
Au dÃ©but, j'avais peur de casser mon cluster. En fait, le Chaos Engineering est super contrÃ´lÃ© : durÃ©e limitÃ©e, scope prÃ©cis, rollback automatique. C'est rassurant.

## 4. Helm simplifie Ã‰NORMÃ‰MENT la vie
DÃ©ployer Prometheus Ã  la main ? Des dizaines de YAML, des CRDs compliquÃ©s. Avec Helm ? Une ligne de commande. Pareil pour ArgoCD, Chaos Mesh, etc.

---

# ğŸ’¡ MES ERREURS ET COMMENT JE LES AI CORRIGÃ‰ES

## Erreur 1 : Cluster avec trop peu de RAM
**ProblÃ¨me :** `minikube start --memory=8192` a Ã©chouÃ© (limite systÃ¨me 7604 MB)
**Solution :** RÃ©duit Ã  `--memory=3500`. Apprendre Ã  dimensionner selon les ressources disponibles.

## Erreur 2 : Port 8080 dÃ©jÃ  utilisÃ©
**ProblÃ¨me :** `kubectl port-forward` Ã©chouait
**Solution :** UtilisÃ© des ports alternatifs (8081, 8082, 8083). Toujours vÃ©rifier avec `lsof -i :PORT`.

## Erreur 3 : Ingress sans IP externe
**ProblÃ¨me :** `kubectl get ingress` affichait `<pending>`
**Solution :** LancÃ© `minikube tunnel` (requiert sudo). L'Ingress a immÃ©diatement obtenu une IP.

## Erreur 4 : OubliÃ© les annotations Prometheus
**ProblÃ¨me :** MÃ©triques custom non scrapÃ©es
**Solution :** AjoutÃ© les annotations `prometheus.io/scrape: "true"` sur le Service. Prometheus a dÃ©couvert l'endpoint automatiquement.

## Erreur 5 : Token GitHub en clair dans le YAML
**ProblÃ¨me :** Presque commitÃ© un token en dur
**Solution :** UtilisÃ© des Secrets Kubernetes + placeholders `REMPLACER_PAR_...` dans les templates.

---

# ğŸ“ COMMANDES QUE J'UTILISE TOUT LE TEMPS

```bash
kubectl get all --all-namespaces
kubectl describe pod <pod-name>
kubectl logs -f <pod-name>
kubectl get events --sort-by='.lastTimestamp'
kubectl top nodes
kubectl top pods
kubectl port-forward svc/<service-name> <local-port>:<remote-port>
helm list --all-namespaces
minikube status
minikube tunnel
```

---

# ğŸ”— RESSOURCES QUI M'ONT AIDÃ‰

- [Kubernetes Official Docs](https://kubernetes.io/docs/)
- [Prometheus Operator](https://prometheus-operator.dev/)
- [Chaos Mesh Documentation](https://chaos-mesh.org/docs/)
- [ArgoCD Getting Started](https://argo-cd.readthedocs.io/en/stable/)
- [GitHub Actions Runners](https://docs.github.com/en/actions/hosting-your-own-runners)
- [Cosign Documentation](https://docs.sigstore.dev/cosign/overview/)
- [Kyverno Policies](https://kyverno.io/policies/)

---

# ğŸ¯ PROCHAINES Ã‰TAPES

1. **Production** : Appliquer ces concepts sur un vrai cluster (EKS, GKE, AKS)
2. **Service Mesh** : DÃ©couvrir Istio ou Linkerd pour la communication inter-services
3. **Multi-cluster** : GÃ©rer plusieurs clusters avec ArgoCD ApplicationSets
4. **Cost Optimization** : Installer Kubecost pour analyser les dÃ©penses
5. **Advanced Security** : Policies Kyverno plus poussÃ©es (NetworkPolicies, PodSecurityStandards)

---

# âœï¸ MON RETOUR D'EXPÃ‰RIENCE GLOBAL

Ce TP Ã©tait intense mais incroyablement formateur. J'ai touchÃ© Ã  toute la stack DevOps moderne :
- Infrastructure (Kubernetes multi-nodes)
- ObservabilitÃ© (Prometheus/Grafana)
- RÃ©silience (Topology Spread + Chaos Engineering)
- CI/CD (GitHub Actions + runners)
- GitOps (ArgoCD)
- SÃ©curitÃ© (Cosign + Kyverno)

Le plus dur ? Patienter pendant les longues installations Helm et comprendre que certains warnings sont normaux.

Le plus satisfaisant ? Voir ArgoCD synchroniser automatiquement mon cluster aprÃ¨s un simple `git push`. C'est magique.

**Si je devais refaire ce TP, je changerais quoi ?**
- DÃ©marrer avec plus de RAM allouÃ©e Ã  minikube
- Documenter au fur et Ã  mesure (pas Ã  la fin)
- Faire des snapshots du cluster Ã  chaque partie validÃ©e

**Ce que je recommande Ã  quelqu'un qui commence :**
1. Ne pas se prÃ©cipiter - lire la doc avant de lancer les commandes
2. Utiliser les scripts de validation pour vÃ©rifier chaque Ã©tape
3. Ne pas avoir peur de dÃ©truire et recrÃ©er le cluster
4. Prendre des notes personnelles (comme ce fichier)

---

# ğŸ“Š STATISTIQUES FINALES

- **Temps total investi** : ~8 heures
- **Namespaces crÃ©Ã©s** : 6 (default, monitoring, chaos-mesh, argocd, renovate, burrito)
- **Deployments** : 12+
- **Services** : 15+
- **Secrets** : 8
- **CRDs installÃ©s** : 50+
- **Fichiers YAML crÃ©Ã©s** : 18
- **Scripts bash** : 4
- **Fichiers documentation** : 5
- **Lignes de code/config** : ~2000
- **Commits Git** : 25+

---

**ğŸ‰ FIN DU TP DEVOPS JOUR 4 - MISSION ACCOMPLIE !**

*"La diffÃ©rence entre un DevOps junior et senior ? Le senior a cassÃ© plus de clusters en production."*

Brahim Hmitti - Octobre 2025


---

## ğŸ“ Concepts ClÃ©s Appris

### 1. Architecture Kubernetes
**HiÃ©rarchie :** `Cluster â†’ Node â†’ Namespace â†’ Deployment â†’ ReplicaSet â†’ Pods`

**Points clÃ©s :**
- Un cluster contient plusieurs nÅ“uds (machines physiques/virtuelles)
- Les namespaces isolent logiquement les ressources
- Les deployments gÃ¨rent automatiquement les ReplicaSets et les pods

### 2. Gestion des Ressources
**LeÃ§ons importantes :**
- Toujours spÃ©cifier le type de ressource : `kubectl delete deployment nom` (pas juste `nom`)
- Le service `kubernetes` (ClusterIP: 10.96.0.1) est systÃ¨me et ne doit jamais Ãªtre supprimÃ©
- Utiliser les labels pour gÃ©rer plusieurs ressources : `kubectl delete all -l app=monapp`

### 3. Architecture RÃ©seau
**Organisation du rÃ©seau :**
- **Pods** : RÃ©seau `10.244.x.x`
- **NÅ“uds** : RÃ©seau `192.168.49.x` (minikube)
- **Control Plane** : Composants maÃ®tres (API, etcd, scheduler)
- **Worker Nodes** : Composants de travail (kubelet, kube-proxy)

### 4. Drivers Minikube
**Choix automatique optimal :**
- **Docker** : Rapide, conteneurs, optimal pour dÃ©veloppement local WSL/Ubuntu
- **VirtualBox** : Plus lent, VMs complÃ¨tes, pour tests avancÃ©s
- **Hyper-V** : Moyen, pour Windows Pro/Enterprise

### 5. Topology Spread Constraints - RÃ©silience Applicative

**ProblÃ©matique :** Ã‰viter qu'une panne d'un nÅ“ud affecte toute l'application (SPOF - Single Point of Failure).

**Solution implÃ©mentÃ©e :** Configuration de contraintes de rÃ©partition topologique.

**Configuration essentielle :**
```yaml
topologySpreadConstraints:
- maxSkew: 1                              # Max 1 pod de diffÃ©rence entre nÅ“uds
  topologyKey: kubernetes.io/hostname     # RÃ©partition par nÅ“ud
  whenUnsatisfiable: DoNotSchedule        # Contrainte stricte
  labelSelector:
    matchLabels:
      app: resilient-app
```

**Modes de contraintes :**
- **`DoNotSchedule`** : Strict - prÃ©fÃ¨re la rÃ©silience (pods en Pending si nÃ©cessaire)
- **`ScheduleAnyway`** : Souple - prÃ©fÃ¨re la disponibilitÃ© (schedules quand mÃªme)

**BÃ©nÃ©fices :**
- **Haute disponibilitÃ©** : 50% de l'app reste opÃ©rationnelle si un nÅ“ud tombe
- **Distribution Ã©quitable** : Ã‰vite la surcharge d'un seul nÅ“ud
- **Production-ready** : Respecte les bonnes pratiques DevOps

---

## âœ… Validation - Monitoring et Tests de Charge

### ğŸ¯ Stack Prometheus DÃ©ployÃ©e et ValidÃ©e

**Infrastructure monitoring :** Prometheus + Grafana + AlertManager opÃ©rationnels

**Validations rÃ©ussies :**
1. âœ… **Repository Helm ajoutÃ©** : prometheus-community accessible
2. âœ… **Stack dÃ©ployÃ©e** : Tous les composants fonctionnels
3. âœ… **Dashboards Kubernetes** : MÃ©triques cluster visibles
4. âœ… **Interface Grafana** : AccÃ¨s via port-forward

### ğŸ¯ Tests de Charge k6 ValidÃ©s

**Infrastructure rÃ©seau :** Ingress NGINX + minikube tunnel

**Validations rÃ©ussies :**
1. âœ… **Addon ingress activÃ©** : NGINX controller dÃ©ployÃ©
2. âœ… **Ingress configurÃ©** : FQDN `.fbi.com` fonctionnel
3. âœ… **Tests k6 adaptÃ©s** : Charge distribuÃ©e via Ingress
4. âœ… **MÃ©triques observÃ©es** : Impact visible en temps rÃ©el dans Grafana

### ğŸ¯ Dashboard Custom et Chaos Engineering ValidÃ©s

**Monitoring applicatif :** Dashboard guestbook `/info` + alerting

**Validations rÃ©ussies :**
1. âœ… **Endpoint `/info` explorÃ©** : MÃ©triques custom identifiÃ©es
2. âœ… **Dashboard crÃ©Ã©** : Panels PromQL fonctionnels
3. âœ… **Alertes configurÃ©es** : Notifications sur KPI critiques
4. âœ… **Chaos Mesh dÃ©ployÃ©** : ExpÃ©riences pod-kill opÃ©rationnelles
5. âœ… **RÃ©silience validÃ©e** : RÃ©cupÃ©ration automatique confirmÃ©e

### ğŸ¯ CI/CD Self-Hosted ValidÃ©

**Infrastructure CI/CD :** GitHub Actions runner dans Kubernetes

**Validations rÃ©ussies :**
1. âœ… **Token GitHub crÃ©Ã©** : Secret Kubernetes configurÃ©
2. âœ… **Runner dÃ©ployÃ©** : Pod fonctionnel dans le cluster
3. âœ… **Enregistrement automatique** : Visible dans GitHub settings
4. âœ… **Workflow testÃ©** : ExÃ©cution rÃ©ussie

**RÃ©sultat final :** J'ai maintenant un environnement DevOps complet : monitoring + chaos engineering + CI/CD.

---

## âœ… Validation - Topology Spread Constraints

### ğŸ¯ Configuration TestÃ©e et ValidÃ©e

**Infrastructure :** Cluster minikube 2 nÅ“uds + 4 pods nginx

**Tests de rÃ©silience rÃ©ussis :**
1. âœ… **RÃ©partition Ã©quitable** : 2 pods par nÅ“ud initialement
2. âœ… **Simulation panne** : `kubectl drain` â†’ Pods Ã©vacuÃ©s, contraintes respectÃ©es
3. âœ… **Remise en service** : `kubectl uncordon` â†’ Redistribution automatique
4. âœ… **Application opÃ©rationnelle** : Service accessible pendant tous les tests

**RÃ©sultat final :** L'application est maintenant parfaitement rÃ©siliente aux pannes de nÅ“uds.

### 6. Stack de Monitoring Prometheus/Grafana

**ProblÃ©matique :** Besoin de surveiller les mÃ©triques du cluster et des applications en temps rÃ©el.

**Solution dÃ©ployÃ©e :** Stack kube-prometheus-stack avec Helm.

**Composants installÃ©s :**
- **Prometheus** : Collecte et stockage des mÃ©triques
- **Grafana** : Dashboards et visualisation
- **AlertManager** : Gestion des alertes

**BÃ©nÃ©fices :**
- **ObservabilitÃ© complÃ¨te** : MÃ©triques cluster + applications
- **Dashboards prÃ©-configurÃ©s** : Kubernetes, nÅ“uds, pods, services
- **Alerting** : Notifications automatiques en cas d'anomalie
- **Interface unified** : Vue d'ensemble centralisÃ©e

### 7. Tests de Charge et Ingress

**ProblÃ©matique :** Valider les performances sous stress et distribuer la charge Ã©quitablement.

**Solution implÃ©mentÃ©e :** 
- **Ingress NGINX** : Distribution de charge et exposition
- **Tests k6** : GÃ©nÃ©ration de charge rÃ©aliste
- **CorrÃ©lation mÃ©triques** : Impact visible dans Grafana

**Configuration clÃ© :**
- Ingress avec FQDN `.fbi.com`
- `minikube tunnel` pour LoadBalancer
- Tests k6 via Ingress (pas port-forward)

**Apprentissages :**
- Port-forward sollicite toujours le mÃªme pod
- Ingress rÃ©partit vraiment la charge
- MÃ©triques temps rÃ©el essentielles pour le dimensionnement

### 8. Dashboard PersonnalisÃ© pour Application MÃ©tier

**ProblÃ©matique :** Suivre les mÃ©triques spÃ©cifiques Ã  mon application (pas seulement l'infra).

**Solution implÃ©mentÃ©e :** Dashboard custom dans Grafana pour l'endpoint `/info` du guestbook.

**Ce que j'ai dÃ©couvert :**
- L'endpoint `/info` expose des mÃ©triques au format Prometheus
- PromQL permet d'extraire et manipuler ces donnÃ©es
- Les graphiques temporels + jauges donnent une vue complÃ¨te

**BÃ©nÃ©fices :**
- **Monitoring applicatif** : MÃ©triques business en plus de l'infra
- **Alerting ciblÃ©** : Notifications sur les KPI critiques
- **Vue unifiÃ©e** : Infra + app dans le mÃªme outil

### 9. Chaos Engineering avec Chaos Mesh

**ProblÃ©matique :** Tester la rÃ©silience en conditions rÃ©elles avant les pannes.

**Solution implÃ©mentÃ©e :** Chaos Mesh pour simuler des pannes contrÃ´lÃ©es (pod-kill).

**Ce que j'ai appris :**
- Chaos Mesh utilise des CRDs pour dÃ©finir les expÃ©riences
- Pod-kill simule les pannes de pods alÃ©atoires
- L'impact est immÃ©diatement visible dans Grafana
- La rÃ©cupÃ©ration automatique fonctionne

**BÃ©nÃ©fices :**
- **Confiance** : J'ai validÃ© la rÃ©silience avant la prod
- **AmÃ©lioration continue** : DÃ©tection des points faibles
- **Monitoring validÃ©** : Les alertes se dÃ©clenchent correctement


---

## ï¿½ Ce que j'ai retenu

**Erreurs que j'ai Ã©vitÃ©es :**
- J'utilise toujours `kubectl delete deployment nom` maintenant (plus jamais juste le nom)
- Je ne touche jamais au service `kubernetes` - j'ai compris que c'est systÃ¨me
- J'ai mÃ©morisÃ© la hiÃ©rarchie : Cluster â†’ Node â†’ Namespace â†’ Deployment â†’ ReplicaSet â†’ Pods

**Choix techniques que j'ai faits :**
- J'ai gardÃ© Docker comme driver minikube - c'est le plus rapide pour le dÃ©veloppement
- J'ai implÃ©mentÃ© les Topology Spread Constraints partout - c'est obligatoire en production
- J'ai testÃ© la rÃ©silience avec `kubectl drain/uncordon` avant chaque dÃ©ploiement

**Ce qui marche vraiment :**
- J'ai installÃ© Prometheus + Grafana - l'observabilitÃ© c'est vital
- J'ai utilisÃ© k6 avec Ingress pour les tests de charge - Ã§a rÃ©partit vraiment la charge
- J'ai compris la diffÃ©rence : port-forward = un seul pod, Ingress = distribution Ã©quitable
- J'ai crÃ©Ã© un dashboard custom pour mon app - les mÃ©triques business c'est clÃ©
- J'ai dÃ©ployÃ© Chaos Mesh - tester la rÃ©silience avant les vraies pannes
- J'ai installÃ© un runner GitHub dans mon cluster - CI/CD maÃ®trisÃ©e
