# ğŸš€ Guide Pratique DevOps - Kubernetes RÃ©silience et Monitoring

---

## ğŸ“‹ **PARTIE 1 : Topology Spread Constraints**

## ğŸ”§ Ã‰tape 1 : PrÃ©paration du Cluster

### CrÃ©er un cluster multi-nÅ“uds
```bash
# Supprimer un cluster existant si nÃ©cessaire
minikube delete

# CrÃ©er un cluster avec 2 nÅ“uds
minikube start --nodes 2 --cpus 3 --memory 4096

# VÃ©rifier les nÅ“uds
kubectl get nodes
```

**RÃ©sultat attendu :**
```
NAME           STATUS   ROLES           AGE   VERSION
minikube       Ready    control-plane   10m   v1.34.0
minikube-m02   Ready    <none>          10m   v1.34.0
```

---

## ğŸ“¦ Ã‰tape 2 : DÃ©ploiement de l'Application RÃ©siliente

### DÃ©ployer l'application
```bash
# Appliquer le deployment avec Topology Spread Constraints
kubectl apply -f resilient-app-deployment.yaml

# CrÃ©er le service d'exposition
kubectl apply -f resilient-app-service.yaml
```

### VÃ©rifier le dÃ©ploiement
```bash
# Voir tous les pods avec leur rÃ©partition
kubectl get pods -o wide | grep resilient

# VÃ©rifier les services
kubectl get services | grep resilient

# Voir le statut du deployment
kubectl get deployment resilient-app
```

**RÃ©sultat attendu :**
- 4 pods dÃ©ployÃ©s
- 2 pods sur chaque nÅ“ud (rÃ©partition Ã©quitable)
- Services crÃ©Ã©s et accessibles

---

## ğŸ§ª Ã‰tape 3 : Tests de Fonctionnement

### Test de base de l'application
```bash
# Tester l'application depuis un pod
kubectl exec -it $(kubectl get pods | grep resilient | head -1 | awk '{print $1}') -- curl localhost

# Voir les dÃ©tails de configuration
kubectl get deployment resilient-app -o yaml | grep -A 10 -B 5 topologySpreadConstraints
```

### VÃ©rifier la rÃ©partition des pods
```bash
# Voir la rÃ©partition dÃ©taillÃ©e
kubectl get pods -l app=resilient-app -o wide

# Compter les pods par nÅ“ud
echo "Pods sur minikube:"
kubectl get pods -o wide | grep resilient | grep minikube | grep -v minikube-m02 | wc -l

echo "Pods sur minikube-m02:"
kubectl get pods -o wide | grep resilient | grep minikube-m02 | wc -l
```

---

## ğŸ”¥ Ã‰tape 4 : Tests de RÃ©silience

### Test 1 - Simulation de panne d'un nÅ“ud
```bash
echo "=== AVANT - RÃ©partition des pods ==="
kubectl get pods -o wide | grep resilient

echo "=== SIMULATION PANNE - Drainage du nÅ“ud minikube-m02 ==="
kubectl drain minikube-m02 --ignore-daemonsets --delete-emptydir-data --force

echo "=== PENDANT - Ã‰tat des pods aprÃ¨s drainage ==="
kubectl get pods -o wide | grep resilient

echo "=== ANALYSE - Pourquoi certains pods sont Pending ==="
kubectl describe pod $(kubectl get pods | grep Pending | head -1 | awk '{print $1}') | grep -A 5 "Events:"
```

### Test 2 - Remise en service
```bash
echo "=== REMISE EN SERVICE du nÅ“ud ==="
kubectl uncordon minikube-m02

echo "=== Attendre la redistribution (5 secondes) ==="
sleep 5

echo "=== APRÃˆS - Nouvelle rÃ©partition ==="
kubectl get pods -o wide | grep resilient
```

### Test 3 - VÃ©rification fonctionnelle aprÃ¨s tests
```bash
echo "=== TEST FONCTIONNEL - L'application fonctionne-t-elle ? ==="
kubectl exec -it $(kubectl get pods | grep resilient | grep Running | head -1 | awk '{print $1}') -- curl localhost | head -3
```

---

## ğŸ“Š Ã‰tape 5 : Validation et Nettoyage

### Valider que tous les critÃ¨res sont respectÃ©s
```bash
echo "=== VALIDATION FINALE ==="

echo "1. Nombre de nÅ“uds disponibles:"
kubectl get nodes | grep Ready | wc -l

echo "2. RÃ©partition Ã©quitable des pods:"
kubectl get pods -l app=resilient-app -o wide

echo "3. Status du deployment:"
kubectl get deployment resilient-app

echo "4. Services accessibles:"
kubectl get services | grep resilient

echo "5. Test application:"
kubectl exec -it $(kubectl get pods | grep resilient | grep Running | head -1 | awk '{print $1}') -- curl -s localhost | grep -o "<title>.*</title>"
```

### Nettoyage (optionnel)
```bash
# Supprimer l'application
kubectl delete -f resilient-app-deployment.yaml
kubectl delete -f resilient-app-service.yaml

# Ou supprimer tout par label
kubectl delete all -l app=resilient-app
```

---

## ğŸ” Commandes de Diagnostic

### Debug en cas de problÃ¨me
```bash
# Voir tous les Ã©vÃ©nements rÃ©cents
kubectl get events --all-namespaces --sort-by='.lastTimestamp' | tail -20

# Diagnostiquer un pod en erreur
kubectl describe pod <nom-du-pod>

# Voir les logs d'un pod
kubectl logs <nom-du-pod>

# VÃ©rifier l'Ã©tat des nÅ“uds
kubectl describe nodes

# Voir les contraintes de topologie appliquÃ©es
kubectl get deployment resilient-app -o jsonpath='{.spec.template.spec.topologySpreadConstraints}' | jq .
```

### Commandes de surveillance
```bash
# Surveiller les pods en temps rÃ©el
kubectl get pods -w

# Voir l'utilisation des ressources
kubectl top nodes
kubectl top pods

# VÃ©rifier les services
kubectl get endpoints
kubectl describe service resilient-app
```

---

## ğŸ“‹ **PARTIE 2 : Stack Monitoring Prometheus/Grafana**

## ğŸ”§ Ã‰tape 6 : Installation de la Stack de Monitoring

### Ajouter le repository Helm Prometheus
```bash
helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
helm repo update
```

### DÃ©ployer la stack kube-prometheus-stack
```bash
helm install prometheus prometheus-community/kube-prometheus-stack --namespace monitoring --create-namespace
```

### VÃ©rifier le dÃ©ploiement
```bash
kubectl get pods -n monitoring
kubectl get services -n monitoring
```

---

## ğŸ”§ Ã‰tape 7 : Configuration des AccÃ¨s Web

### AccÃ©der Ã  Grafana
```bash
kubectl port-forward -n monitoring svc/prometheus-grafana 3000:80 &
```

### AccÃ©der Ã  Prometheus
```bash
kubectl port-forward -n monitoring svc/prometheus-kube-prometheus-prometheus 9090:9090 &
```

### RÃ©cupÃ©rer les credentials Grafana
```bash
kubectl get secret -n monitoring prometheus-grafana -o jsonpath="{.data.admin-password}" | base64 --decode ; echo
```

---

## ğŸ”§ Ã‰tape 8 : Validation du Monitoring

### Tester l'accÃ¨s aux interfaces
```bash
curl http://localhost:3000/api/health
curl http://localhost:9090/-/healthy
```

### VÃ©rifier les dashboards Kubernetes
```bash
kubectl get configmaps -n monitoring | grep dashboard
```

---

## ğŸ“‹ **PARTIE 3 : Tests de Charge avec Ingress**

## ğŸ”§ Ã‰tape 9 : Configuration Ingress

### Activer l'addon ingress minikube
```bash
minikube addons enable ingress
kubectl get pods -n ingress-nginx
```

### CrÃ©er l'Ingress pour guestbook
```bash
kubectl apply -f - <<EOF
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: guestbook-ingress
  annotations:
    nginx.ingress.kubernetes.io/rewrite-target: /
spec:
  rules:
  - host: guestbook.fbi.com
    http:
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: guestbook-service
            port:
              number: 80
EOF
```

### DÃ©marrer minikube tunnel
```bash
minikube tunnel &
```

---

## ğŸ”§ Ã‰tape 10 : Tests de Charge k6

### Tester l'accÃ¨s via Ingress
```bash
echo "$(minikube ip) guestbook.fbi.com" | sudo tee -a /etc/hosts
curl http://guestbook.fbi.com
```

### CrÃ©er le script de test k6
```bash
cat > load-test.js <<EOF
import http from 'k6/http';
import { check } from 'k6';

export let options = {
  stages: [
    { duration: '2m', target: 10 },
    { duration: '5m', target: 50 },
    { duration: '2m', target: 0 },
  ],
};

export default function () {
  let response = http.get('http://guestbook.fbi.com');
  check(response, {
    'status is 200': (r) => r.status === 200,
  });
}
EOF
```

### Lancer les tests k6
```bash
k6 run load-test.js
```

---

## ğŸ”§ Ã‰tape 11 : Observation des MÃ©triques

### Surveiller pendant les tests
```bash
kubectl get pods -w
kubectl top nodes
kubectl top pods
```

### VÃ©rifier les mÃ©triques dans Grafana
```bash
echo "AccÃ©dez Ã  http://localhost:3000"
echo "Username: admin"
echo "Password: $(kubectl get secret -n monitoring prometheus-grafana -o jsonpath="{.data.admin-password}" | base64 --decode)"
```

ğŸš€ **J'ai maintenant un monitoring complet avec tests de performance validÃ©s !**
